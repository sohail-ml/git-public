{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r-YGx3KtRSr"
   },
   "source": [
    "# cardekho.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtkQbtzdY1Vi"
   },
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ydJr6bQPpBou"
   },
   "outputs": [],
   "source": [
    "#Import standard libraries\n",
    "#testing git update 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler, MaxAbsScaler,RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats.mstats import normaltest\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J14GMEjoLPsv"
   },
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8NtAwZFX_jr"
   },
   "source": [
    "###Authenticate bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sIXDUgm7YHfC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery==1.25.0\n",
      "  Downloading google_cloud_bigquery-1.25.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[K     |████████████████████████████████| 169 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (3.16.0)\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
      "  Downloading google_resumable_media-0.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.35.0)\n",
      "Requirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.16.0)\n",
      "Collecting google-cloud-core<2.0dev,>=1.1.0\n",
      "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.31.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.53.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (57.4.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (21.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.7.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.10)\n",
      "Installing collected packages: google-resumable-media, google-cloud-core, google-cloud-bigquery\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-storage 1.42.0 requires google-resumable-media<3.0dev,>=1.3.0; python_version >= \"3.6\", but you have google-resumable-media 0.5.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-bigquery-1.25.0 google-cloud-core-1.7.2 google-resumable-media-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Install the Google Cloud BigQuery library\n",
    "!pip install --user google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2-0n98JY_vT"
   },
   "source": [
    "### Pull the dataframe from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uYl-No1yTlfi"
   },
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "# SQL query to get a fields from dataset which prints the 10 records\n",
    "SELECT \n",
    "    *\n",
    "# TODO 3\n",
    "FROM\n",
    "    `linear_regression.car_dekho`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE3znEfL_Wcs"
   },
   "source": [
    "# EXPLORE AND CLEAN DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1631588312149,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "-ZnFAbAZ67hv",
    "outputId": "ecf0fea1-80a1-40bf-c5cf-c1da0f8b3f94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4340, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vpnez4Z1hSB0"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original\n",
    "data = df.copy()\n",
    "\n",
    "# The first word in the name columns looks like the manufacturer of the car.\n",
    "# Since, we are not provided with this information in a separate column, we can\n",
    "# extract it from the \"name\" column.\n",
    "#data[\"manufacturer\"] = data.name.str.split(n=1,expand=True)[0]\n",
    "#data = data.drop(\"name\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCs9NqNj2QFE"
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1934,
     "status": "ok",
     "timestamp": 1631588321634,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "AxupCl6rm5MD",
    "outputId": "2a5f8d61-1614-4fd8-d4b5-07b38622d20c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f86609d3d50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "re_arrange_cols = ['year', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner', 'manufacturer', 'selling_price']\n",
    "\n",
    "data = data[re_arrange_cols]\n",
    "\n",
    "fig, (ax1, ax2,ax3,ax4,ax5,ax6,ax7) = plt.subplots(7)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(5)\n",
    "ax1.scatter(data.year, data.selling_price)\n",
    "ax2.scatter(data.km_driven, data.selling_price)\n",
    "ax3.scatter(data.fuel, data.selling_price)\n",
    "ax4.scatter(data.seller_type, data.selling_price)\n",
    "ax5.scatter(data.transmission, data.selling_price)\n",
    "ax6.scatter(data.owner, data.selling_price)\n",
    "ax7.scatter(data.manufacturer, data.selling_price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2636,
     "status": "ok",
     "timestamp": 1631588331019,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "zUOw2xjFtWpe",
    "outputId": "0d0c517f-8234-49c0-c172-ad6e6eb69f84"
   },
   "outputs": [],
   "source": [
    "re_arrange_cols = ['year', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner', 'manufacturer', 'selling_price']\n",
    "\n",
    "data = data[re_arrange_cols]\n",
    "\n",
    "fig, (ax1, ax2,ax3,ax4,ax5,ax6,ax7) = plt.subplots(7)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(10)\n",
    "ax1.hist(data.year)\n",
    "ax2.hist(data.km_driven)\n",
    "ax3.hist(data.fuel)\n",
    "ax4.hist(data.seller_type)\n",
    "ax5.hist(data.transmission)\n",
    "ax6.hist(data.owner)\n",
    "ax7.hist(data.manufacturer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1631580630888,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "0ExpGWvn0jBo",
    "outputId": "07ac62af-c06c-4593-a0b0-0d710067689b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>q25</th>\n",
       "      <th>median</th>\n",
       "      <th>q75</th>\n",
       "      <th>range</th>\n",
       "      <th>iqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1992.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2013.090783</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km_driven</th>\n",
       "      <td>1.0</td>\n",
       "      <td>806599.0</td>\n",
       "      <td>66215.777419</td>\n",
       "      <td>35000.00</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>806598.0</td>\n",
       "      <td>55000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selling_price</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>8900000.0</td>\n",
       "      <td>504127.311751</td>\n",
       "      <td>208749.75</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>8880000.0</td>\n",
       "      <td>391250.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   min        max           mean        q25    median  \\\n",
       "year            1992.0     2020.0    2013.090783    2011.00    2014.0   \n",
       "km_driven          1.0   806599.0   66215.777419   35000.00   60000.0   \n",
       "selling_price  20000.0  8900000.0  504127.311751  208749.75  350000.0   \n",
       "\n",
       "                    q75      range        iqr  \n",
       "year             2016.0       28.0       5.00  \n",
       "km_driven       90000.0   806598.0   55000.00  \n",
       "selling_price  600000.0  8880000.0  391250.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select just the rows desired from the 'describe' method and add in the 'median'\n",
    "#Check the min,max, mean,median,range and iqr for the numeric fields\n",
    "stats_df = data.describe()\n",
    "stats_df.loc['range'] = stats_df.loc['max'] - stats_df.loc['min']\n",
    "\n",
    "out_fields = ['min','max','mean','25%','50%','75%','range']\n",
    "stats_df = stats_df.loc[out_fields]\n",
    "\n",
    "stats_df.rename({'50%':'median','25%':'q25','75%':'q75'},inplace=True)\n",
    "\n",
    "stats_df.loc['iqr'] = stats_df.loc['q75'] - stats_df.loc['q25']\n",
    "\n",
    "stats_df.T\n",
    "\n",
    "# year: range shows that our data is spread over 28 years, staring from\n",
    "# 1992 and ending in 2020. \n",
    "# Selling price range from 20000 to 89000000\n",
    "#km driven range frmo 1 to 806599 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1631579511945,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "Pz2Smq1i9DkP",
    "outputId": "ac067402-30ac-4f13-de04-517622a8b00e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">year</th>\n",
       "      <th colspan=\"2\" halign=\"left\">km_driven</th>\n",
       "      <th colspan=\"2\" halign=\"left\">selling_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automatic</th>\n",
       "      <td>2015.895939</td>\n",
       "      <td>2017</td>\n",
       "      <td>44462.824873</td>\n",
       "      <td>38500</td>\n",
       "      <td>1.526170e+06</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manual</th>\n",
       "      <td>2014.857143</td>\n",
       "      <td>2015</td>\n",
       "      <td>60548.743961</td>\n",
       "      <td>52600</td>\n",
       "      <td>4.792861e+05</td>\n",
       "      <td>425000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year            km_driven        selling_price         \n",
       "                     mean median          mean median          mean   median\n",
       "transmission                                                                \n",
       "Automatic     2015.895939   2017  44462.824873  38500  1.526170e+06  1100000\n",
       "Manual        2014.857143   2015  60548.743961  52600  4.792861e+05   425000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying multiple functions at once - 2 methods\n",
    "data.groupby('transmission').agg(['mean','median'])\n",
    "#Shows Automatic cars sells for more and also newer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1631579511945,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "nErllaJEniZc",
    "outputId": "c0bb24d7-5eb0-4765-822a-f61abadc6985"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ambassador</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>4.300000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>2014.018182</td>\n",
       "      <td>63937.872727</td>\n",
       "      <td>2.014509e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>2016.314286</td>\n",
       "      <td>43869.828571</td>\n",
       "      <td>3.174000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrolet</th>\n",
       "      <td>2013.198582</td>\n",
       "      <td>67986.418440</td>\n",
       "      <td>2.622482e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datsun</th>\n",
       "      <td>2016.513514</td>\n",
       "      <td>29564.351351</td>\n",
       "      <td>2.970269e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiat</th>\n",
       "      <td>2014.090909</td>\n",
       "      <td>74792.636364</td>\n",
       "      <td>3.670909e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Force</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>37516.000000</td>\n",
       "      <td>3.460000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ford</th>\n",
       "      <td>2015.307692</td>\n",
       "      <td>58595.671795</td>\n",
       "      <td>6.581538e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honda</th>\n",
       "      <td>2015.527094</td>\n",
       "      <td>50184.349754</td>\n",
       "      <td>6.113300e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyundai</th>\n",
       "      <td>2015.271704</td>\n",
       "      <td>47738.172026</td>\n",
       "      <td>5.058617e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isuzu</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1.500000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaguar</th>\n",
       "      <td>2012.600000</td>\n",
       "      <td>54945.200000</td>\n",
       "      <td>1.973000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeep</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>27346.000000</td>\n",
       "      <td>1.530000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kia</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.300000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Land</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>84500.000000</td>\n",
       "      <td>3.462250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>1.842500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mahindra</th>\n",
       "      <td>2015.096886</td>\n",
       "      <td>73005.747405</td>\n",
       "      <td>6.742318e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maruti</th>\n",
       "      <td>2015.337931</td>\n",
       "      <td>55281.829885</td>\n",
       "      <td>4.422094e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mercedes-Benz</th>\n",
       "      <td>2015.500000</td>\n",
       "      <td>33462.500000</td>\n",
       "      <td>3.271036e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitsubishi</th>\n",
       "      <td>2011.600000</td>\n",
       "      <td>133574.000000</td>\n",
       "      <td>8.580000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nissan</th>\n",
       "      <td>2014.031746</td>\n",
       "      <td>68028.714286</td>\n",
       "      <td>4.475555e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Renault</th>\n",
       "      <td>2015.410959</td>\n",
       "      <td>47421.287671</td>\n",
       "      <td>4.193767e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skoda</th>\n",
       "      <td>2013.420000</td>\n",
       "      <td>71864.300000</td>\n",
       "      <td>5.661200e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tata</th>\n",
       "      <td>2014.201613</td>\n",
       "      <td>65389.088710</td>\n",
       "      <td>3.536774e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>2014.390244</td>\n",
       "      <td>87151.390244</td>\n",
       "      <td>1.046726e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen</th>\n",
       "      <td>2013.711340</td>\n",
       "      <td>71986.195876</td>\n",
       "      <td>4.836598e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>2015.250000</td>\n",
       "      <td>86748.000000</td>\n",
       "      <td>2.556250e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      year      km_driven  selling_price\n",
       "manufacturer                                            \n",
       "Ambassador     2012.000000   50000.000000   4.300000e+05\n",
       "Audi           2014.018182   63937.872727   2.014509e+06\n",
       "BMW            2016.314286   43869.828571   3.174000e+06\n",
       "Chevrolet      2013.198582   67986.418440   2.622482e+05\n",
       "Datsun         2016.513514   29564.351351   2.970269e+05\n",
       "Fiat           2014.090909   74792.636364   3.670909e+05\n",
       "Force          2014.000000   37516.000000   3.460000e+05\n",
       "Ford           2015.307692   58595.671795   6.581538e+05\n",
       "Honda          2015.527094   50184.349754   6.113300e+05\n",
       "Hyundai        2015.271704   47738.172026   5.058617e+05\n",
       "Isuzu          2018.000000   40000.000000   1.500000e+06\n",
       "Jaguar         2012.600000   54945.200000   1.973000e+06\n",
       "Jeep           2018.000000   27346.000000   1.530000e+06\n",
       "Kia            2019.000000   10000.000000   1.300000e+06\n",
       "Land           2016.000000   84500.000000   3.462250e+06\n",
       "MG             2019.000000   16000.000000   1.842500e+06\n",
       "Mahindra       2015.096886   73005.747405   6.742318e+05\n",
       "Maruti         2015.337931   55281.829885   4.422094e+05\n",
       "Mercedes-Benz  2015.500000   33462.500000   3.271036e+06\n",
       "Mitsubishi     2011.600000  133574.000000   8.580000e+05\n",
       "Nissan         2014.031746   68028.714286   4.475555e+05\n",
       "Renault        2015.410959   47421.287671   4.193767e+05\n",
       "Skoda          2013.420000   71864.300000   5.661200e+05\n",
       "Tata           2014.201613   65389.088710   3.536774e+05\n",
       "Toyota         2014.390244   87151.390244   1.046726e+06\n",
       "Volkswagen     2013.711340   71986.195876   4.836598e+05\n",
       "Volvo          2015.250000   86748.000000   2.556250e+06"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('manufacturer').agg('mean','median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2ex5zFJLqk2"
   },
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NEFtvEr1YT5"
   },
   "source": [
    "### Explore Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1631585380138,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "DB5_L3VR1osU",
    "outputId": "3ba06fdc-b1a2-4833-e76d-5ec2c32be73a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='selling_price', ylabel='Density'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(np.log(df.selling_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1631581563948,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "0NC5nULr1tuZ",
    "outputId": "89c37272-0e76-499a-89b4-238c42582292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormaltestResult(statistic=13.155628356574784, pvalue=0.0013908862038200577)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaltest(np.log(df.selling_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Vf7GPrBp1yf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test boxcox\n",
    "target_boxcox = boxcox(df.selling_price)\n",
    "sns.kdeplot(target_boxcox[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhPf4baA13bv"
   },
   "source": [
    "### Set up prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1631589367385,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "eRls283c4sz6",
    "outputId": "b8128e5e-0410-4da0-db2d-070034e9584f"
   },
   "outputs": [],
   "source": [
    "#Create subset of data for prediction\n",
    "all_cols = ['year', 'selling_price', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner', 'name']\n",
    "sub_cols = [ 'year','km_driven','name','transmission','fuel','seller_type', 'selling_price']\n",
    "small_data = data[all_cols]\n",
    "small_data.selling_price = boxcox(small_data.selling_price)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1631589370491,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "yDEwVDtTuFiT",
    "outputId": "b840008c-a277-4b9e-8e74-91702f5884b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fuel', 'seller_type', 'transmission', 'owner', 'name'], dtype='object')\n",
      "name\n",
      "fuel\n",
      "owner\n",
      "seller_type\n",
      "transmission\n"
     ]
    }
   ],
   "source": [
    "# Do the one hot encoding\n",
    "# Lets find the colms which need one hot encoding\n",
    "ohc_cols = small_data.columns[small_data.dtypes == \"object\"]\n",
    "print(ohc_cols)\n",
    "# Determine how many extra columns would be created\n",
    "num_ohc_cols = (small_data[ohc_cols]\n",
    "                .apply(lambda x: x.nunique())\n",
    "                .sort_values(ascending=False))\n",
    "# Copy of the data\n",
    "data_ohc = small_data.copy()\n",
    "\n",
    "# The encoders\n",
    "le = LabelEncoder()\n",
    "ohc = OneHotEncoder()\n",
    "\n",
    "for col in num_ohc_cols.index:\n",
    "    print(col)\n",
    "    # Integer encode the string categories\n",
    "    dat = le.fit_transform(data_ohc[col]).astype(np.int)\n",
    "    \n",
    "    # Remove the original column from the dataframe\n",
    "    data_ohc = data_ohc.drop(col, axis=1)\n",
    "\n",
    "    # One hot encode the data--this returns a sparse array\n",
    "    new_dat = ohc.fit_transform(dat.reshape(-1,1))\n",
    "\n",
    "    # Create unique column names\n",
    "    n_cols = new_dat.shape[1]\n",
    "    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n",
    "\n",
    "    # Create the new dataframe\n",
    "    new_df = pd.DataFrame(new_dat.toarray(), \n",
    "                          index=data_ohc.index, \n",
    "                          columns=col_names)\n",
    "\n",
    "    # Append the new data to the dataframe\n",
    "    data_ohc = pd.concat([data_ohc, new_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysZu5ECCLvX-"
   },
   "source": [
    "# FIT AND PREDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYfgZHYdhErB"
   },
   "source": [
    "###Split the data with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yx-b08W5L6uu"
   },
   "outputs": [],
   "source": [
    "X = data_ohc.drop('selling_price', axis = 1)\n",
    "y = data_ohc.selling_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_PbVeTF1feUP"
   },
   "outputs": [],
   "source": [
    "kf = KFold(shuffle=True, random_state=72018,n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1631589381745,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "f1Srdfx0fy2v",
    "outputId": "fc73dc47-e443-49a3-f58a-d397ddbe7edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index: [ 0  2  3  4  5  7  8  9 10 11] 2893\n",
      "Test index: [ 1  6 14 15 17 18 20 22 26 30] 1447\n",
      "\n",
      "Train index: [ 0  1  2  4  6  7  8 10 11 12] 2893\n",
      "Test index: [ 3  5  9 16 19 21 23 24 27 31] 1447\n",
      "\n",
      "Train index: [ 1  3  5  6  9 14 15 16 17 18] 2894\n",
      "Test index: [ 0  2  4  7  8 10 11 12 13 25] 1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(X):\n",
    "  print(\"Train index:\",train_index[:10],len(train_index))\n",
    "  print(\"Test index:\", test_index[:10],len(test_index))\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TeWO4-nhSyB"
   },
   "source": [
    "###Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P-xBrVqXg99h"
   },
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "r = RobustScaler()\n",
    "lr = LinearRegression()\n",
    "mi = MinMaxScaler()\n",
    "max = MaxAbsScaler()\n",
    "\n",
    "#estimator = Pipeline([(\"scaler\",max), (\"regression\",lr)])\n",
    "estimator = Pipeline([(\"regression\",lr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOncw4WoirkB"
   },
   "source": [
    "###Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EMhdGkQGiCFJ"
   },
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(estimator,X,y, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1631589457608,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "HdRL_RNNl24c",
    "outputId": "db23bde2-baba-4230-b18a-1a697285b658"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.639541</td>\n",
       "      <td>8.865270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.143125</td>\n",
       "      <td>-2643.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.718447</td>\n",
       "      <td>10.152108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.889089</td>\n",
       "      <td>10.546127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.639541</td>\n",
       "      <td>9.407433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y            p\n",
       "0   9.639541     8.865270\n",
       "1  10.143125 -2643.034632\n",
       "2  10.718447    10.152108\n",
       "3  10.889089    10.546127\n",
       "4   9.639541     9.407433"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series = pd.Series(y)\n",
    "p_series = pd.Series(predictions)\n",
    "frame = { 'y': y, 'p': predictions }\n",
    "\n",
    "pd.DataFrame(frame).head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1631589461492,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "RJ_9bkRJ4TZZ",
    "outputId": "ddfb06f6-8043-4520-d1f1-df63c04bbbe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-178581631960.87598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1631587367056,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "ec0h2EOpzksl",
    "outputId": "edfa2e47-607f-4249-e460-4853c7ebd891"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "ax = plt.axes()\n",
    "# we are going to use y_test, y_test_pred\n",
    "ax.scatter(y, predictions, alpha=.5)\n",
    "\n",
    "ax.set(xlabel='Ground truth', \n",
    "       ylabel='Predictions',\n",
    "       title='Ames, Iowa House Price Predictions vs Truth, using Linear Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHHsqk7Cwe7d"
   },
   "source": [
    "##Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1631613777807,
     "user": {
      "displayName": "SOHAIL AJAZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09832138505281235982"
     },
     "user_tz": -540
    },
    "id": "4WcNQPjRwjjD",
    "outputId": "57828e2a-eb6e-4ee1-e412-a7a3e9751258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.geomspace(1e-9, 1e0, num=10)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.60407895838418, tolerance: 0.11979868407987752\n",
      "  positive)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.1741851317124, tolerance: 0.11400585707424443\n",
      "  positive)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.800677775504024, tolerance: 0.11652334613701712\n",
      "  positive)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.07156345114702, tolerance: 0.11979868407987752\n",
      "  positive)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.350849187908857, tolerance: 0.11400585707424443\n",
      "  positive)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.088231147853953, tolerance: 0.11652334613701712\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "coefs = []\n",
    "for alpha in alphas:\n",
    "    las = Lasso(alpha=alpha, max_iter=100000)\n",
    "    \n",
    "    estimator = Pipeline([        \n",
    "        (\"lasso_regression\", las)])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    \n",
    "    score = r2_score(y, predictions)\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1e-09, 0.8036138082797633),\n",
       " (1e-08, 0.8382774887410896),\n",
       " (1e-07, 0.8405065593188167),\n",
       " (1e-06, 0.8408492704449193),\n",
       " (1e-05, 0.8428033712961572),\n",
       " (0.0001, 0.8229989406164365),\n",
       " (0.001, 0.7039954304553759),\n",
       " (0.01, 0.6776573132571964),\n",
       " (0.1, 0.48879777077893616),\n",
       " (1.0, 0.32014922213220254)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(alphas,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.31887859e-02, -5.88241361e-07, -3.92698113e-02, ...,\n",
       "        7.35634720e-02,  5.02410058e-01, -1.59450148e-16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso(alpha=1e-05).fit(X, y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.semilogx(alphas, scores, '-o')\n",
    "plt.xlabel('$\\\\alpha$')\n",
    "plt.ylabel('$R^2$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228554485954538"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have found the hyperparameter (alpha~1e-2=0.01)\n",
    "# make the model and train it on ALL the data\n",
    "# Then release it into the wild .....\n",
    "#best_estimator = Pipeline([                   \n",
    "#                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "#                    (\"lasso_regression\", Lasso(alpha=0.01))\n",
    "#                 ])\n",
    "\n",
    "best_estimator = Pipeline([                   \n",
    "                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "                    (\"regression\", lr)\n",
    "                 ])\n",
    "\n",
    "best_estimator.fit(X, y)\n",
    "best_estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.4484e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.22757e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.05445e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.75212e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.4244e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.23609e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.08439e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.63795e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.43362e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.44552e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.8713e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.64929e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.83901e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.12575e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.8828e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.26611e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.40122e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.13759e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.73197e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.70258e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.41479e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.23748e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.02958e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.7167e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.78948e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.38542e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.0446e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.38929e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.77337e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.40255e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.0432e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.19532e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.79138e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.75432e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.65423e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.21526e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=9.52794e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.15408e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=5.67543e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.03709e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.69832e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.1773e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.1286e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.29044e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.72364e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.22837e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.93503e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.31787e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.33693e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.63606e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.9643e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.45509e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=9.39874e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.66821e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.58379e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.02301e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=9.43418e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.72371e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.1134e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.02678e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f31dcb61710>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf = PolynomialFeatures(degree=2)\n",
    "alphas = np.geomspace(4, 20, 20)\n",
    "scores=[]\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha, max_iter=100000)\n",
    "\n",
    "    estimator = Pipeline([\n",
    "        (\"polynomial_features\", pf),\n",
    "        (\"ridge_regression\", ridge)])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    score = r2_score(y, predictions)\n",
    "    scores.append(score)\n",
    "\n",
    "plt.plot(alphas, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228554485954538"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have found the hyperparameter (alpha~1e-2=0.01)\n",
    "# make the model and train it on ALL the data\n",
    "# Then release it into the wild .....\n",
    "#best_estimator = Pipeline([\n",
    "#                    (\"scaler\", s),\n",
    "#                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "#                    (\"lasso_regression\", Lasso(alpha=0.03))])\n",
    "\n",
    "best_estimator = Pipeline([\n",
    "                    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "                    (\"regression\", lr)\n",
    "])\n",
    "\n",
    "best_estimator.fit(X, y)\n",
    "best_estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_importances = pd.DataFrame(zip(best_estimator.named_steps[\"make_higher_degree\"].get_feature_names(),\n",
    "#                 best_estimator.named_steps[\"lasso_regression\"].coef_,\n",
    "#))\n",
    "df_importances = pd.DataFrame(zip(best_estimator.named_steps[\"make_higher_degree\"].get_feature_names(),\n",
    "                 best_estimator.named_steps[\"regression\"].coef_,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_dict = dict(zip(list(range(len(X.columns.values))), X.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'year',\n",
       " 1: 'km_driven',\n",
       " 2: 'manufacturer_0',\n",
       " 3: 'manufacturer_1',\n",
       " 4: 'manufacturer_2',\n",
       " 5: 'manufacturer_3',\n",
       " 6: 'manufacturer_4',\n",
       " 7: 'manufacturer_5',\n",
       " 8: 'manufacturer_6',\n",
       " 9: 'manufacturer_7',\n",
       " 10: 'manufacturer_8',\n",
       " 11: 'manufacturer_9',\n",
       " 12: 'manufacturer_10',\n",
       " 13: 'manufacturer_11',\n",
       " 14: 'manufacturer_12',\n",
       " 15: 'manufacturer_13',\n",
       " 16: 'manufacturer_14',\n",
       " 17: 'manufacturer_15',\n",
       " 18: 'manufacturer_16',\n",
       " 19: 'manufacturer_17',\n",
       " 20: 'manufacturer_18',\n",
       " 21: 'manufacturer_19',\n",
       " 22: 'manufacturer_20',\n",
       " 23: 'manufacturer_21',\n",
       " 24: 'manufacturer_22',\n",
       " 25: 'manufacturer_23',\n",
       " 26: 'manufacturer_24',\n",
       " 27: 'manufacturer_25',\n",
       " 28: 'manufacturer_26',\n",
       " 29: 'manufacturer_27',\n",
       " 30: 'manufacturer_28',\n",
       " 31: 'fuel_0',\n",
       " 32: 'fuel_1',\n",
       " 33: 'fuel_2',\n",
       " 34: 'fuel_3',\n",
       " 35: 'fuel_4',\n",
       " 36: 'seller_type_0',\n",
       " 37: 'seller_type_1',\n",
       " 38: 'seller_type_2',\n",
       " 39: 'transmission_0',\n",
       " 40: 'transmission_1'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>x22^2</td>\n",
       "      <td>-7.126464e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x22</td>\n",
       "      <td>-7.124434e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>x22 x35</td>\n",
       "      <td>-3.797802e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>x22 x39</td>\n",
       "      <td>-3.797802e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>x22 x36</td>\n",
       "      <td>-3.596758e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>x22 x37</td>\n",
       "      <td>-3.529706e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>x22 x32</td>\n",
       "      <td>-3.328663e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>x22 x40</td>\n",
       "      <td>-3.328663e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>x27^2</td>\n",
       "      <td>-2.591345e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>x27</td>\n",
       "      <td>-2.586126e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>x36^2</td>\n",
       "      <td>-1.985979e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>x36</td>\n",
       "      <td>-1.985978e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>x37</td>\n",
       "      <td>-1.898883e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>x37^2</td>\n",
       "      <td>-1.898882e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>x14</td>\n",
       "      <td>-1.878617e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>x14 x39</td>\n",
       "      <td>-1.874072e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>x14^2</td>\n",
       "      <td>-1.874072e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>x23^2</td>\n",
       "      <td>-1.754061e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>x23</td>\n",
       "      <td>-1.749166e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>x27 x39</td>\n",
       "      <td>-1.664832e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>x10^2</td>\n",
       "      <td>-1.557379e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>x10</td>\n",
       "      <td>-1.554300e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>x8 x40</td>\n",
       "      <td>-1.553472e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>x8^2</td>\n",
       "      <td>-1.553472e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x8</td>\n",
       "      <td>-1.553404e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>x27 x36</td>\n",
       "      <td>-1.297725e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>x27 x37</td>\n",
       "      <td>-1.293620e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>x23 x39</td>\n",
       "      <td>-1.251122e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>x10 x39</td>\n",
       "      <td>-1.127501e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>x27 x35</td>\n",
       "      <td>-1.013949e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>x36 x40</td>\n",
       "      <td>-9.986241e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>x36 x39</td>\n",
       "      <td>-9.873554e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>x14 x35</td>\n",
       "      <td>-9.615271e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>x37 x40</td>\n",
       "      <td>-9.585169e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>x32 x36</td>\n",
       "      <td>-9.529545e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>x14 x36</td>\n",
       "      <td>-9.486266e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>x23 x35</td>\n",
       "      <td>-9.423831e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>x37 x39</td>\n",
       "      <td>-9.403652e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>x12^2</td>\n",
       "      <td>-9.288888e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>x12</td>\n",
       "      <td>-9.283954e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>x27 x40</td>\n",
       "      <td>-9.265126e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>x14 x37</td>\n",
       "      <td>-9.254455e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>x32 x37</td>\n",
       "      <td>-9.194912e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>x14 x32</td>\n",
       "      <td>-9.125450e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>x23 x37</td>\n",
       "      <td>-8.783045e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>x23 x36</td>\n",
       "      <td>-8.757560e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>x27 x32</td>\n",
       "      <td>-8.716017e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>x10 x35</td>\n",
       "      <td>-8.434973e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>x12 x39</td>\n",
       "      <td>-8.354376e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>x8 x35</td>\n",
       "      <td>-8.240362e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>x23 x32</td>\n",
       "      <td>-8.116775e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>x10 x37</td>\n",
       "      <td>-8.023705e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>x10 x36</td>\n",
       "      <td>-7.926022e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>x35 x36</td>\n",
       "      <td>-7.873814e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>x8 x37</td>\n",
       "      <td>-7.851779e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>x8 x36</td>\n",
       "      <td>-7.682939e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>x35 x37</td>\n",
       "      <td>-7.557449e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>x8 x32</td>\n",
       "      <td>-7.294357e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>x10 x32</td>\n",
       "      <td>-7.138818e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>x27 x31</td>\n",
       "      <td>-7.057942e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>x12 x37</td>\n",
       "      <td>-6.115082e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>x12 x36</td>\n",
       "      <td>-6.091825e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x3</td>\n",
       "      <td>-5.561906e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>x3^2</td>\n",
       "      <td>-5.556776e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>x3 x39</td>\n",
       "      <td>-5.556776e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>x29 x39</td>\n",
       "      <td>-5.235145e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>x23 x40</td>\n",
       "      <td>-5.029385e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>x28 x39</td>\n",
       "      <td>-4.926694e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>x20 x39</td>\n",
       "      <td>-4.917945e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>x31^2</td>\n",
       "      <td>-4.347081e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>x31 x40</td>\n",
       "      <td>-4.347081e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>x10 x40</td>\n",
       "      <td>-4.298784e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>x31</td>\n",
       "      <td>-4.134133e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>x12 x35</td>\n",
       "      <td>-3.986824e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>x28 x36</td>\n",
       "      <td>-3.934006e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>x28 x37</td>\n",
       "      <td>-3.838440e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>x20 x37</td>\n",
       "      <td>-3.830969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>x20 x36</td>\n",
       "      <td>-3.718275e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>x11 x39</td>\n",
       "      <td>-3.332072e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>x3 x35</td>\n",
       "      <td>-3.175113e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>x29</td>\n",
       "      <td>-3.051377e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>x29^2</td>\n",
       "      <td>-2.960394e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>x3 x37</td>\n",
       "      <td>-2.858548e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>x3 x36</td>\n",
       "      <td>-2.698228e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>x28^2</td>\n",
       "      <td>-2.681279e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>x11 x37</td>\n",
       "      <td>-2.592702e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>x28</td>\n",
       "      <td>-2.587129e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>x12 x32</td>\n",
       "      <td>-2.582516e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>x11 x36</td>\n",
       "      <td>-2.547158e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>x3 x32</td>\n",
       "      <td>-2.381663e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>x20^2</td>\n",
       "      <td>-2.331679e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>x20</td>\n",
       "      <td>-2.321531e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>x31 x36</td>\n",
       "      <td>-2.281875e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>x20 x35</td>\n",
       "      <td>-2.258326e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>x31 x37</td>\n",
       "      <td>-2.065206e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>x28 x35</td>\n",
       "      <td>-2.042455e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>x29 x35</td>\n",
       "      <td>-2.012549e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>x21 x39</td>\n",
       "      <td>-1.965939e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>x12 x34</td>\n",
       "      <td>-1.797166e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>x5 x39</td>\n",
       "      <td>-1.652180e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x0</td>\n",
       "      <td>-1.583723e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>x29 x37</td>\n",
       "      <td>-1.515813e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>x29 x36</td>\n",
       "      <td>-1.444580e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>x32 x39</td>\n",
       "      <td>-1.155084e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>x29 x32</td>\n",
       "      <td>-9.478451e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>x12 x40</td>\n",
       "      <td>-9.345126e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>x12 x31</td>\n",
       "      <td>-9.223817e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>x5 x35</td>\n",
       "      <td>-8.997988e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>x19 x37</td>\n",
       "      <td>-8.512234e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>x0 x40</td>\n",
       "      <td>-8.083545e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>x0 x39</td>\n",
       "      <td>-8.040557e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>x20 x32</td>\n",
       "      <td>-7.986580e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>x19 x36</td>\n",
       "      <td>-7.046407e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>x28 x32</td>\n",
       "      <td>-6.388223e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>x15 x35</td>\n",
       "      <td>-6.279123e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>x0 x38</td>\n",
       "      <td>-5.977787e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>x26 x39</td>\n",
       "      <td>-5.922957e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>x0 x37</td>\n",
       "      <td>-5.079229e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>x0 x36</td>\n",
       "      <td>-5.066927e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>x0 x35</td>\n",
       "      <td>-4.064891e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>x0 x34</td>\n",
       "      <td>-4.039841e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>x0 x32</td>\n",
       "      <td>-3.996413e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>x0 x31</td>\n",
       "      <td>-3.977219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>x34 x40</td>\n",
       "      <td>-3.458128e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>x34^2</td>\n",
       "      <td>-3.458128e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>x34</td>\n",
       "      <td>-3.457947e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>x1 x39</td>\n",
       "      <td>-3.268966e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>x1 x40</td>\n",
       "      <td>-3.268962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>x2 x35</td>\n",
       "      <td>-3.234518e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>x0 x17</td>\n",
       "      <td>-2.920783e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>x32^2</td>\n",
       "      <td>-2.809376e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>x32</td>\n",
       "      <td>-2.809340e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>x19 x39</td>\n",
       "      <td>-2.582122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>x40^2</td>\n",
       "      <td>-2.416920e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>x40</td>\n",
       "      <td>-2.416881e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>x1 x37</td>\n",
       "      <td>-2.178859e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>x1 x36</td>\n",
       "      <td>-2.178857e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>x1 x38</td>\n",
       "      <td>-2.178848e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>x20 x34</td>\n",
       "      <td>-1.945406e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>x34 x36</td>\n",
       "      <td>-1.745585e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>x34 x37</td>\n",
       "      <td>-1.712542e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>x1 x33</td>\n",
       "      <td>-1.409504e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>x0 x7</td>\n",
       "      <td>-1.312340e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>x11 x35</td>\n",
       "      <td>-1.307930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>x1 x34</td>\n",
       "      <td>-1.279712e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>x1 x31</td>\n",
       "      <td>-1.279701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>x1 x35</td>\n",
       "      <td>-1.279701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>x1 x32</td>\n",
       "      <td>-1.279701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>x0 x25</td>\n",
       "      <td>-8.791778e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>x0 x26</td>\n",
       "      <td>-7.465617e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>x0 x19</td>\n",
       "      <td>-7.399587e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>x0 x4</td>\n",
       "      <td>-7.011904e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>x0 x5</td>\n",
       "      <td>-6.999547e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>x0 x21</td>\n",
       "      <td>-6.937543e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>x0 x30</td>\n",
       "      <td>-6.654738e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>x0 x11</td>\n",
       "      <td>-6.409966e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>x0 x2</td>\n",
       "      <td>-6.210366e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>x0 x15</td>\n",
       "      <td>-6.198135e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>x0 x24</td>\n",
       "      <td>-6.131768e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>x0 x29</td>\n",
       "      <td>-5.890272e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>x0 x20</td>\n",
       "      <td>-5.865154e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>x0 x28</td>\n",
       "      <td>-5.805162e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>x0 x3</td>\n",
       "      <td>-5.443866e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>x0 x12</td>\n",
       "      <td>-4.793545e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>x13</td>\n",
       "      <td>-4.694094e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>x0 x18</td>\n",
       "      <td>-4.677231e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>x9</td>\n",
       "      <td>-4.545105e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>x0 x10</td>\n",
       "      <td>-3.689002e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>x0 x23</td>\n",
       "      <td>-3.369558e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>x1 x16</td>\n",
       "      <td>-3.366578e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>x0 x8</td>\n",
       "      <td>-3.143890e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x18</td>\n",
       "      <td>-2.988741e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>x0 x14</td>\n",
       "      <td>-2.802293e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>x1 x9</td>\n",
       "      <td>-2.503549e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>x1 x13</td>\n",
       "      <td>-2.482563e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>x1 x6</td>\n",
       "      <td>-2.425399e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>x1 x18</td>\n",
       "      <td>-2.392662e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>x1 x24</td>\n",
       "      <td>-2.181246e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>x1 x17</td>\n",
       "      <td>-2.179115e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>x1 x2</td>\n",
       "      <td>-2.178331e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>x1 x14</td>\n",
       "      <td>-2.178052e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>x1 x7</td>\n",
       "      <td>-2.177969e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>x1 x4</td>\n",
       "      <td>-2.177871e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>x1 x19</td>\n",
       "      <td>-2.177809e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>x1 x3</td>\n",
       "      <td>-2.177788e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>x1 x11</td>\n",
       "      <td>-2.177783e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>x1 x26</td>\n",
       "      <td>-2.177781e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>x1 x21</td>\n",
       "      <td>-2.177779e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>x1 x20</td>\n",
       "      <td>-2.177752e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>x1 x12</td>\n",
       "      <td>-2.177735e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>x1 x27</td>\n",
       "      <td>-2.177732e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>x1 x8</td>\n",
       "      <td>-2.177731e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>x1 x5</td>\n",
       "      <td>-2.177729e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>x1 x29</td>\n",
       "      <td>-2.177711e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>x1 x10</td>\n",
       "      <td>-2.177705e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>x1 x25</td>\n",
       "      <td>-2.177686e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>x1 x23</td>\n",
       "      <td>-2.177680e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>x1 x28</td>\n",
       "      <td>-2.177671e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>x1 x15</td>\n",
       "      <td>-2.177637e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>x1 x30</td>\n",
       "      <td>-2.177400e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>x1 x22</td>\n",
       "      <td>-2.176449e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>x0 x27</td>\n",
       "      <td>-2.103459e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>x15</td>\n",
       "      <td>-8.216670e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x2</td>\n",
       "      <td>-7.861033e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>x0 x16</td>\n",
       "      <td>-6.795639e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>x0 x33</td>\n",
       "      <td>-4.560766e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.158601e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>x0 x9</td>\n",
       "      <td>-1.343978e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>x0 x13</td>\n",
       "      <td>-1.253368e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>x0 x6</td>\n",
       "      <td>-9.714377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>x18 x32</td>\n",
       "      <td>-9.826190e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>x18 x40</td>\n",
       "      <td>-9.826190e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>x24 x40</td>\n",
       "      <td>-3.051588e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>x24^2</td>\n",
       "      <td>-3.051588e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>x24 x37</td>\n",
       "      <td>-3.051588e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>x24 x35</td>\n",
       "      <td>-3.051588e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>x33</td>\n",
       "      <td>-3.037868e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>x18^2</td>\n",
       "      <td>-2.316523e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>x18 x36</td>\n",
       "      <td>-2.316523e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>x16 x39</td>\n",
       "      <td>-3.366698e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>x16 x37</td>\n",
       "      <td>-3.366698e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>x16^2</td>\n",
       "      <td>-3.366698e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>x16 x32</td>\n",
       "      <td>-3.366698e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>x33 x36</td>\n",
       "      <td>-2.273435e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>x33 x39</td>\n",
       "      <td>-2.273435e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>x33^2</td>\n",
       "      <td>-2.273435e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>x28 x33</td>\n",
       "      <td>-2.273435e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>x9^2</td>\n",
       "      <td>-6.673140e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>x9 x40</td>\n",
       "      <td>-6.673140e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>x9 x37</td>\n",
       "      <td>-6.673140e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>x9 x32</td>\n",
       "      <td>-6.673139e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>x13^2</td>\n",
       "      <td>-6.207331e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>x13 x32</td>\n",
       "      <td>-6.207330e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>x13 x40</td>\n",
       "      <td>-6.207330e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>x13 x37</td>\n",
       "      <td>-6.207330e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>x6 x40</td>\n",
       "      <td>-4.851579e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>x6 x37</td>\n",
       "      <td>-4.851579e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>x6 x35</td>\n",
       "      <td>-4.851579e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>x6^2</td>\n",
       "      <td>-4.851422e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>x2 x10</td>\n",
       "      <td>-8.746726e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>x2 x6</td>\n",
       "      <td>-7.454615e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>x2 x19</td>\n",
       "      <td>-3.828760e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>x2 x13</td>\n",
       "      <td>-2.858469e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>x2 x11</td>\n",
       "      <td>-1.880651e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>x2 x25</td>\n",
       "      <td>-1.440092e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>x2 x30</td>\n",
       "      <td>-9.322321e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>x2 x34</td>\n",
       "      <td>-9.253043e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>x2 x16</td>\n",
       "      <td>-7.810114e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>x2 x4</td>\n",
       "      <td>-7.369216e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>x2 x36</td>\n",
       "      <td>-7.226220e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>x2 x33</td>\n",
       "      <td>-7.027268e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>x2 x27</td>\n",
       "      <td>-6.579626e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>x2 x3</td>\n",
       "      <td>-5.348610e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>x2 x28</td>\n",
       "      <td>-2.117417e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>x2 x21</td>\n",
       "      <td>-2.083667e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>x2 x26</td>\n",
       "      <td>-2.040146e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>x2 x24</td>\n",
       "      <td>-1.811884e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>x2 x18</td>\n",
       "      <td>-1.397993e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>x2 x29</td>\n",
       "      <td>-6.252776e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>x3 x5</td>\n",
       "      <td>-4.405365e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>x3 x4</td>\n",
       "      <td>-3.694822e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>x3 x6</td>\n",
       "      <td>-6.616929e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>x16 x36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>x18 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>x16 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>x18 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>x18 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>x18 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>x16 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>x18 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>x18 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>x18 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>x16 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>x18 x37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>x16 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>x18 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>x16 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>x18 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>x16 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>x17 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>x16 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>x17 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>x18 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>x18 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>x17 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>x18 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>x18 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>x17 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>x16 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>x17 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>x18 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>x17 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>x17 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>x17 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>x17 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>x17 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>x17 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>x17 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>x17 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>x17 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>x17 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>x17 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>x17 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>x18 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>x17 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>x18 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>x16 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>x4 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>x16 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>x16 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>x14 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>x14 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>x3 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>x14 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>x14 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>x14 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>x14 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>x14 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>x14 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>x14 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>x14 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>x14 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>x14 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>x14 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>x14 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>x14 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>x14 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>x13 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>x13 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>x13 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>x13 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>x13 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>x13 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>x3 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>x13 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>x13 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>x13 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>x3 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>x14 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>x14 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>x14 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>x13 x36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>x16 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>x3 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>x14 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>x16 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>x16 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>x16 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>x16 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>x16 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>x16 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>x16 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>x16 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>x15 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>x15 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>x15 x36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>x15 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>x15 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>x15 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>x15 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>x15 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>x15 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>x3 x8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>x14 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>x15 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>x4 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>x15 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>x15 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>x3 x9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>x15 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>x15 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>x15 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>x15 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>x15 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>x15 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>x15 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>x15 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>x19 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>x20 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>x19 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>x28 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>x28 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>x27 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>x27 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>x27 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>x27 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>x27 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>x27 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>x26 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>x26 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>x26 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>x26 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>x26 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>x26 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>x26 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>x26 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>x25 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>x25 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>x25 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>x25 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>x25 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>x25 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>x25 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>x25 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>x24 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>x24 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>x24 x36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>x24 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>x24 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>x28 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>x24 x32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>x28 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>x29 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>x37 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>x36 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>x36 x37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>x34 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>x34 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>x34 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>x33 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>x33 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>x33 x37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>x33 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>x33 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>x32 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>x32 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>x32 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>x31 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>x31 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>x31 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>x31 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>x31 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>x31 x32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>x30 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>x30 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>x30 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>x30 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>x30 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>x30 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>x29 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>x29 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>x29 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>x29 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>x19 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>x24 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>x24 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>x21 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>x21 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>x21 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>x21 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>x21 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>x21 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>x21 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>x20 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>x20 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>x20 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>x20 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>x20 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>x20 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>x20 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>x20 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>x13 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>x20 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>x20 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>x19 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>x19 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>x19 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>x19 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>x19 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>x19 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>x19 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>x19 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>x19 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>x19 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>x19 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>x21 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>x24 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>x21 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>x21 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>x24 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>x24 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>x24 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>x24 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>x23 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>x23 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>x23 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>x23 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>x23 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>x23 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>x23 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>x23 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>x23 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>x23 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>x23 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>x22 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>x22 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>x22 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>x22 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>x22 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>x22 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>x22 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>x22 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>x22 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>x22 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>x22 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>x22 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>x21 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>x21 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>x21 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>x13 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>x15 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>x13 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>x7 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>x7 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>x7 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>x7 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>x7 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>x7 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>x7 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>x7 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>x7 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>x7 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>x7 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>x7 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>x7 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>x7 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>x7 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>x7 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>x7 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>x7 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>x6 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>x6 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>x6 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>x6 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>x6 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>x6 x32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>x7 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>x6 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>x6 x36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>x6 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>x6 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>x7 x8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>x7 x9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>x7 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>x6 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>x6 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>x7 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>x7 x32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>x8 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>x8 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>x8 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>x8 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>x8 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>x8 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>x8 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>x8 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>x8 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>x4 x6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>x8 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>x8 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>x4 x5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>x3 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>x8 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>x7 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>x8 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>x8 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>x7 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>x13 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>x7 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>x4 x7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>x8 x9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>x8 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>x8 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>x8 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>x8 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>x8 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>x8 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>x8 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>x8 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>x8 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>x8 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>x6 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>x6 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>x6 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>x4 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>x4 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>x4 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>x4 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>x4 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>x4 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>x4 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>x5 x6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>x5 x8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>x5 x9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>x5 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>x5 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>x5 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>x5 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>x5 x7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>x5 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>x4 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>x4 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>x4 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>x4 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>x4 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>x4 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>x4 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>x4 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>x4 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>x4 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>x4 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>x4 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>x4 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>x4 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>x4 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>x4 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>x4 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>x5 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>x5 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>x5 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>x6 x9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>x6 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>x6 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>x6 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>x6 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>x6 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>x6 x8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>x6 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>x6 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>x6 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>x6 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>x6 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>x6 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>x6 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>x6 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>x6 x7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>x4 x8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>x5 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>x5 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>x5 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>x5 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>x5 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>x5 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>x5 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>x5 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>x5 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>x5 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>x5 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>x5 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>x5 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>x5 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>x5 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>x4 x9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>x8 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>x8 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>x7 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>x9 x10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>x11 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>x11 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>x11 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>x39 x40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>x11 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>x11 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>x11 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>x11 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>x3 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>x11 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>x11 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>x11 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>x11 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>x11 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>x3 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>x3 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>x11 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>x3 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>x11 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>x11 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>x10 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>x10 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>x10 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>x3 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>x10 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>x10 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>x3 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>x11 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>x3 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>x3 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>x3 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>x11 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>x11 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>x11 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>x11 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>x11 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>x3 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>x10 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>x3 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>x12 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>x3 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>x3 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>x3 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>x3 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>x3 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>x3 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>x13 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>x12 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>x13 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>x13 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>x13 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>x13 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>x13 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>x13 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>x13 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>x13 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>x13 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>x3 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>x3 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>x12 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>x12 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>x12 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>x12 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>x12 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>x12 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>x12 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>x12 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>x3 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>x12 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>x12 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>x12 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>x12 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>x12 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>x12 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>x12 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>x12 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>x12 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>x10 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>x11 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>x10 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>x9 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>x9 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>x9 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>x9 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>x9 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>x9 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>x9 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>x9 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>x9 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>x9 x36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>x9 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>x9 x35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>x9 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>x9 x33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>x9 x31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>x10 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>x9 x30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>x9 x29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>x9 x28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>x9 x27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>x9 x26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>x9 x25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>x9 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>x9 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>x9 x38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>x9 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>x10 x16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>x10 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>x3 x34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>x10 x14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>x10 x15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>x9 x11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>x10 x17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>x10 x18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>x10 x12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>x10 x19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>x10 x20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>x10 x21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>x10 x22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>x9 x39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>x10 x23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>x10 x24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>x10 x13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>x3 x7</td>\n",
       "      <td>2.842171e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>x2 x8</td>\n",
       "      <td>2.631229e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>x2 x15</td>\n",
       "      <td>8.224532e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>x1^2</td>\n",
       "      <td>1.731060e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>x2 x31</td>\n",
       "      <td>3.957723e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>x2 x39</td>\n",
       "      <td>5.892176e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>x2 x23</td>\n",
       "      <td>7.987389e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>x2 x38</td>\n",
       "      <td>1.143263e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>x2 x14</td>\n",
       "      <td>1.640088e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>x2 x22</td>\n",
       "      <td>1.680345e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>x2 x9</td>\n",
       "      <td>1.734957e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>x2 x17</td>\n",
       "      <td>1.742184e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>x2 x20</td>\n",
       "      <td>2.060574e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>x2 x5</td>\n",
       "      <td>5.332357e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>x2 x7</td>\n",
       "      <td>6.334466e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>x2 x12</td>\n",
       "      <td>1.059544e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>x0 x1</td>\n",
       "      <td>7.189110e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>x18 x35</td>\n",
       "      <td>7.509676e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>x18 x39</td>\n",
       "      <td>7.509676e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>x15^2</td>\n",
       "      <td>7.261969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>x15 x40</td>\n",
       "      <td>7.261969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>x15 x37</td>\n",
       "      <td>7.261969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>x0^2</td>\n",
       "      <td>8.566299e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>x2^2</td>\n",
       "      <td>1.097110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>x2 x40</td>\n",
       "      <td>1.097110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>x2 x37</td>\n",
       "      <td>1.097110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x6</td>\n",
       "      <td>1.951962e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>x16</td>\n",
       "      <td>1.344726e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>x0 x22</td>\n",
       "      <td>5.917567e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>x24</td>\n",
       "      <td>1.098767e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>x30 x36</td>\n",
       "      <td>1.709684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>x39</td>\n",
       "      <td>2.416752e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>x39^2</td>\n",
       "      <td>2.416920e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>x2 x32</td>\n",
       "      <td>3.245489e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>x30 x37</td>\n",
       "      <td>3.520428e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>x10 x38</td>\n",
       "      <td>3.759362e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>x5 x32</td>\n",
       "      <td>4.793043e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>x30 x39</td>\n",
       "      <td>5.230111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>x30 x32</td>\n",
       "      <td>5.230111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>x30^2</td>\n",
       "      <td>5.230111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>x30</td>\n",
       "      <td>5.458683e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>x4 x35</td>\n",
       "      <td>5.914063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>x15 x32</td>\n",
       "      <td>6.286385e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x1</td>\n",
       "      <td>6.945141e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>x11</td>\n",
       "      <td>8.577444e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>x32 x40</td>\n",
       "      <td>8.741461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>x11^2</td>\n",
       "      <td>8.885128e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>x20 x31</td>\n",
       "      <td>9.198457e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>x11 x32</td>\n",
       "      <td>1.019306e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>x4 x37</td>\n",
       "      <td>1.043262e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>x21 x35</td>\n",
       "      <td>1.216998e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>x4 x36</td>\n",
       "      <td>1.286413e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>x35 x39</td>\n",
       "      <td>1.396778e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>x21 x36</td>\n",
       "      <td>1.610816e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>x5 x34</td>\n",
       "      <td>1.645894e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>x4 x32</td>\n",
       "      <td>1.738268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>x21 x37</td>\n",
       "      <td>1.751295e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>x5 x37</td>\n",
       "      <td>1.934338e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>x5 x36</td>\n",
       "      <td>2.004459e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>x21 x32</td>\n",
       "      <td>2.145113e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>x25 x36</td>\n",
       "      <td>2.210622e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>x25 x37</td>\n",
       "      <td>2.232761e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>x28 x40</td>\n",
       "      <td>2.245415e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>x29 x40</td>\n",
       "      <td>2.274752e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>x4 x39</td>\n",
       "      <td>2.329675e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>x4^2</td>\n",
       "      <td>2.329675e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x4</td>\n",
       "      <td>2.331478e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>x26 x35</td>\n",
       "      <td>2.541153e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>x20 x40</td>\n",
       "      <td>2.586266e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>x5 x31</td>\n",
       "      <td>2.713397e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>x19 x35</td>\n",
       "      <td>2.748913e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>x12 x38</td>\n",
       "      <td>2.918019e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>x26 x36</td>\n",
       "      <td>3.059073e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>x26 x37</td>\n",
       "      <td>3.100424e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>x21</td>\n",
       "      <td>3.269991e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>x21^2</td>\n",
       "      <td>3.362110e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>x35 x40</td>\n",
       "      <td>3.577056e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>x26 x32</td>\n",
       "      <td>3.618344e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>x25 x39</td>\n",
       "      <td>3.853097e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x5</td>\n",
       "      <td>3.929690e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>x5^2</td>\n",
       "      <td>3.938797e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>x19 x32</td>\n",
       "      <td>4.176136e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>x11 x40</td>\n",
       "      <td>4.220585e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>x35^2</td>\n",
       "      <td>4.973834e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>x35</td>\n",
       "      <td>4.973836e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>x28 x38</td>\n",
       "      <td>5.091166e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>x20 x38</td>\n",
       "      <td>5.217565e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>x21 x40</td>\n",
       "      <td>5.328050e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>x5 x40</td>\n",
       "      <td>5.590977e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>x26</td>\n",
       "      <td>5.999575e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>x11 x38</td>\n",
       "      <td>6.028373e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>x26^2</td>\n",
       "      <td>6.159497e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>x26 x40</td>\n",
       "      <td>6.751793e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>x25 x35</td>\n",
       "      <td>6.776996e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>x19^2</td>\n",
       "      <td>6.925049e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>x19</td>\n",
       "      <td>6.969981e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>x19 x40</td>\n",
       "      <td>7.183262e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>x25 x32</td>\n",
       "      <td>8.403031e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>x19 x38</td>\n",
       "      <td>8.480914e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>x25 x38</td>\n",
       "      <td>1.073664e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>x25 x40</td>\n",
       "      <td>1.132693e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>x7 x39</td>\n",
       "      <td>1.296512e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>x25^2</td>\n",
       "      <td>1.518003e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>x25</td>\n",
       "      <td>1.520331e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>x7 x36</td>\n",
       "      <td>1.675313e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>x7 x37</td>\n",
       "      <td>1.680972e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>x32 x38</td>\n",
       "      <td>1.844352e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>x38 x40</td>\n",
       "      <td>1.932972e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>x38 x39</td>\n",
       "      <td>1.951890e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>x35 x38</td>\n",
       "      <td>2.040510e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>x7 x40</td>\n",
       "      <td>2.059774e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>x7 x35</td>\n",
       "      <td>3.356286e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>x7^2</td>\n",
       "      <td>3.356286e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x7</td>\n",
       "      <td>3.362557e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>x38^2</td>\n",
       "      <td>3.884862e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>x38</td>\n",
       "      <td>3.884863e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>x17 x35</td>\n",
       "      <td>5.682463e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>x17 x36</td>\n",
       "      <td>5.698108e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>x17 x37</td>\n",
       "      <td>5.753457e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>x17 x32</td>\n",
       "      <td>5.769101e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>x17 x39</td>\n",
       "      <td>1.145156e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>x17^2</td>\n",
       "      <td>1.145156e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x17</td>\n",
       "      <td>1.145637e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1\n",
       "713    x22^2 -7.126464e+01\n",
       "23       x22 -7.124434e+01\n",
       "726  x22 x35 -3.797802e+01\n",
       "730  x22 x39 -3.797802e+01\n",
       "727  x22 x36 -3.596758e+01\n",
       "728  x22 x37 -3.529706e+01\n",
       "723  x22 x32 -3.328663e+01\n",
       "731  x22 x40 -3.328663e+01\n",
       "798    x27^2 -2.591345e+01\n",
       "28       x27 -2.586126e+01\n",
       "888    x36^2 -1.985979e+01\n",
       "37       x36 -1.985978e+01\n",
       "38       x37 -1.898883e+01\n",
       "893    x37^2 -1.898882e+01\n",
       "15       x14 -1.878617e+01\n",
       "550  x14 x39 -1.874072e+01\n",
       "525    x14^2 -1.874072e+01\n",
       "732    x23^2 -1.754061e+01\n",
       "24       x23 -1.749166e+01\n",
       "810  x27 x39 -1.664832e+01\n",
       "407    x10^2 -1.557379e+01\n",
       "11       x10 -1.554300e+01\n",
       "374   x8 x40 -1.553472e+01\n",
       "342     x8^2 -1.553472e+01\n",
       "9         x8 -1.553404e+01\n",
       "807  x27 x36 -1.297725e+01\n",
       "808  x27 x37 -1.293620e+01\n",
       "748  x23 x39 -1.251122e+01\n",
       "436  x10 x39 -1.127501e+01\n",
       "806  x27 x35 -1.013949e+01\n",
       "892  x36 x40 -9.986241e+00\n",
       "891  x36 x39 -9.873554e+00\n",
       "546  x14 x35 -9.615271e+00\n",
       "896  x37 x40 -9.585169e+00\n",
       "862  x32 x36 -9.529545e+00\n",
       "547  x14 x36 -9.486266e+00\n",
       "744  x23 x35 -9.423831e+00\n",
       "895  x37 x39 -9.403652e+00\n",
       "468    x12^2 -9.288888e+00\n",
       "13       x12 -9.283954e+00\n",
       "811  x27 x40 -9.265126e+00\n",
       "548  x14 x37 -9.254455e+00\n",
       "863  x32 x37 -9.194912e+00\n",
       "543  x14 x32 -9.125450e+00\n",
       "746  x23 x37 -8.783045e+00\n",
       "745  x23 x36 -8.757560e+00\n",
       "803  x27 x32 -8.716017e+00\n",
       "432  x10 x35 -8.434973e+00\n",
       "495  x12 x39 -8.354376e+00\n",
       "369   x8 x35 -8.240362e+00\n",
       "741  x23 x32 -8.116775e+00\n",
       "434  x10 x37 -8.023705e+00\n",
       "433  x10 x36 -7.926022e+00\n",
       "883  x35 x36 -7.873814e+00\n",
       "371   x8 x37 -7.851779e+00\n",
       "370   x8 x36 -7.682939e+00\n",
       "884  x35 x37 -7.557449e+00\n",
       "366   x8 x32 -7.294357e+00\n",
       "429  x10 x32 -7.138818e+00\n",
       "802  x27 x31 -7.057942e+00\n",
       "493  x12 x37 -6.115082e+00\n",
       "492  x12 x36 -6.091825e+00\n",
       "4         x3 -5.561906e+00\n",
       "162     x3^2 -5.556776e+00\n",
       "198   x3 x39 -5.556776e+00\n",
       "835  x29 x39 -5.235145e+00\n",
       "749  x23 x40 -5.029385e+00\n",
       "823  x28 x39 -4.926694e+00\n",
       "691  x20 x39 -4.917945e+00\n",
       "848    x31^2 -4.347081e+00\n",
       "857  x31 x40 -4.347081e+00\n",
       "437  x10 x40 -4.298784e+00\n",
       "32       x31 -4.134133e+00\n",
       "491  x12 x35 -3.986824e+00\n",
       "820  x28 x36 -3.934006e+00\n",
       "821  x28 x37 -3.838440e+00\n",
       "689  x20 x37 -3.830969e+00\n",
       "688  x20 x36 -3.718275e+00\n",
       "466  x11 x39 -3.332072e+00\n",
       "194   x3 x35 -3.175113e+00\n",
       "30       x29 -3.051377e+00\n",
       "825    x29^2 -2.960394e+00\n",
       "196   x3 x37 -2.858548e+00\n",
       "195   x3 x36 -2.698228e+00\n",
       "812    x28^2 -2.681279e+00\n",
       "464  x11 x37 -2.592702e+00\n",
       "29       x28 -2.587129e+00\n",
       "488  x12 x32 -2.582516e+00\n",
       "463  x11 x36 -2.547158e+00\n",
       "191   x3 x32 -2.381663e+00\n",
       "672    x20^2 -2.331679e+00\n",
       "21       x20 -2.321531e+00\n",
       "853  x31 x36 -2.281875e+00\n",
       "687  x20 x35 -2.258326e+00\n",
       "854  x31 x37 -2.065206e+00\n",
       "819  x28 x35 -2.042455e+00\n",
       "831  x29 x35 -2.012549e+00\n",
       "711  x21 x39 -1.965939e+00\n",
       "490  x12 x34 -1.797166e+00\n",
       "271   x5 x39 -1.652180e+00\n",
       "1         x0 -1.583723e+00\n",
       "833  x29 x37 -1.515813e+00\n",
       "832  x29 x36 -1.444580e+00\n",
       "865  x32 x39 -1.155084e+00\n",
       "828  x29 x32 -9.478451e-01\n",
       "496  x12 x40 -9.345126e-01\n",
       "487  x12 x31 -9.223817e-01\n",
       "267   x5 x35 -8.997988e-01\n",
       "668  x19 x37 -8.512234e-01\n",
       "82    x0 x40 -8.083545e-01\n",
       "81    x0 x39 -8.040557e-01\n",
       "684  x20 x32 -7.986580e-01\n",
       "667  x19 x36 -7.046407e-01\n",
       "816  x28 x32 -6.388223e-01\n",
       "572  x15 x35 -6.279123e-01\n",
       "80    x0 x38 -5.977787e-01\n",
       "796  x26 x39 -5.922957e-01\n",
       "79    x0 x37 -5.079229e-01\n",
       "78    x0 x36 -5.066927e-01\n",
       "77    x0 x35 -4.064891e-01\n",
       "76    x0 x34 -4.039841e-01\n",
       "74    x0 x32 -3.996413e-01\n",
       "73    x0 x31 -3.977219e-01\n",
       "881  x34 x40 -3.458128e-01\n",
       "875    x34^2 -3.458128e-01\n",
       "35       x34 -3.457947e-01\n",
       "121   x1 x39 -3.268966e-01\n",
       "122   x1 x40 -3.268962e-01\n",
       "156   x2 x35 -3.234518e-01\n",
       "59    x0 x17 -2.920783e-01\n",
       "858    x32^2 -2.809376e-01\n",
       "33       x32 -2.809340e-01\n",
       "670  x19 x39 -2.582122e-01\n",
       "902    x40^2 -2.416920e-01\n",
       "41       x40 -2.416881e-01\n",
       "119   x1 x37 -2.178859e-01\n",
       "118   x1 x36 -2.178857e-01\n",
       "120   x1 x38 -2.178848e-01\n",
       "686  x20 x34 -1.945406e-01\n",
       "877  x34 x36 -1.745585e-01\n",
       "878  x34 x37 -1.712542e-01\n",
       "115   x1 x33 -1.409504e-01\n",
       "49     x0 x7 -1.312340e-01\n",
       "462  x11 x35 -1.307930e-01\n",
       "116   x1 x34 -1.279712e-01\n",
       "113   x1 x31 -1.279701e-01\n",
       "117   x1 x35 -1.279701e-01\n",
       "114   x1 x32 -1.279701e-01\n",
       "67    x0 x25 -8.791778e-02\n",
       "68    x0 x26 -7.465617e-02\n",
       "61    x0 x19 -7.399587e-02\n",
       "46     x0 x4 -7.011904e-02\n",
       "47     x0 x5 -6.999547e-02\n",
       "63    x0 x21 -6.937543e-02\n",
       "72    x0 x30 -6.654738e-02\n",
       "53    x0 x11 -6.409966e-02\n",
       "44     x0 x2 -6.210366e-02\n",
       "57    x0 x15 -6.198135e-02\n",
       "66    x0 x24 -6.131768e-02\n",
       "71    x0 x29 -5.890272e-02\n",
       "62    x0 x20 -5.865154e-02\n",
       "70    x0 x28 -5.805162e-02\n",
       "45     x0 x3 -5.443866e-02\n",
       "54    x0 x12 -4.793545e-02\n",
       "14       x13 -4.694094e-02\n",
       "60    x0 x18 -4.677231e-02\n",
       "10        x9 -4.545105e-02\n",
       "52    x0 x10 -3.689002e-02\n",
       "65    x0 x23 -3.369558e-02\n",
       "98    x1 x16 -3.366578e-02\n",
       "50     x0 x8 -3.143890e-02\n",
       "19       x18 -2.988741e-02\n",
       "56    x0 x14 -2.802293e-02\n",
       "91     x1 x9 -2.503549e-02\n",
       "95    x1 x13 -2.482563e-02\n",
       "88     x1 x6 -2.425399e-02\n",
       "100   x1 x18 -2.392662e-02\n",
       "106   x1 x24 -2.181246e-02\n",
       "99    x1 x17 -2.179115e-02\n",
       "84     x1 x2 -2.178331e-02\n",
       "96    x1 x14 -2.178052e-02\n",
       "89     x1 x7 -2.177969e-02\n",
       "86     x1 x4 -2.177871e-02\n",
       "101   x1 x19 -2.177809e-02\n",
       "85     x1 x3 -2.177788e-02\n",
       "93    x1 x11 -2.177783e-02\n",
       "108   x1 x26 -2.177781e-02\n",
       "103   x1 x21 -2.177779e-02\n",
       "102   x1 x20 -2.177752e-02\n",
       "94    x1 x12 -2.177735e-02\n",
       "109   x1 x27 -2.177732e-02\n",
       "90     x1 x8 -2.177731e-02\n",
       "87     x1 x5 -2.177729e-02\n",
       "111   x1 x29 -2.177711e-02\n",
       "92    x1 x10 -2.177705e-02\n",
       "107   x1 x25 -2.177686e-02\n",
       "105   x1 x23 -2.177680e-02\n",
       "110   x1 x28 -2.177671e-02\n",
       "97    x1 x15 -2.177637e-02\n",
       "112   x1 x30 -2.177400e-02\n",
       "104   x1 x22 -2.176449e-02\n",
       "69    x0 x27 -2.103459e-02\n",
       "16       x15 -8.216670e-03\n",
       "3         x2 -7.861033e-03\n",
       "58    x0 x16 -6.795639e-03\n",
       "75    x0 x33 -4.560766e-03\n",
       "0          1 -3.158601e-03\n",
       "51     x0 x9 -1.343978e-03\n",
       "55    x0 x13 -1.253368e-03\n",
       "48     x0 x6 -9.714377e-04\n",
       "641  x18 x32 -9.826190e-05\n",
       "649  x18 x40 -9.826190e-05\n",
       "766  x24 x40 -3.051588e-05\n",
       "750    x24^2 -3.051588e-05\n",
       "763  x24 x37 -3.051588e-05\n",
       "761  x24 x35 -3.051588e-05\n",
       "34       x33 -3.037868e-05\n",
       "627    x18^2 -2.316523e-05\n",
       "645  x18 x36 -2.316523e-05\n",
       "601  x16 x39 -3.366698e-06\n",
       "599  x16 x37 -3.366698e-06\n",
       "578    x16^2 -3.366698e-06\n",
       "594  x16 x32 -3.366698e-06\n",
       "870  x33 x36 -2.273435e-06\n",
       "873  x33 x39 -2.273435e-06\n",
       "867    x33^2 -2.273435e-06\n",
       "817  x28 x33 -2.273435e-06\n",
       "375     x9^2 -6.673140e-07\n",
       "406   x9 x40 -6.673140e-07\n",
       "403   x9 x37 -6.673140e-07\n",
       "398   x9 x32 -6.673139e-07\n",
       "497    x13^2 -6.207331e-07\n",
       "516  x13 x32 -6.207330e-07\n",
       "524  x13 x40 -6.207330e-07\n",
       "521  x13 x37 -6.207330e-07\n",
       "307   x6 x40 -4.851579e-07\n",
       "304   x6 x37 -4.851579e-07\n",
       "302   x6 x35 -4.851579e-07\n",
       "273     x6^2 -4.851422e-07\n",
       "131   x2 x10 -8.746726e-11\n",
       "127    x2 x6 -7.454615e-11\n",
       "140   x2 x19 -3.828760e-11\n",
       "134   x2 x13 -2.858469e-11\n",
       "132   x2 x11 -1.880651e-11\n",
       "146   x2 x25 -1.440092e-11\n",
       "151   x2 x30 -9.322321e-12\n",
       "155   x2 x34 -9.253043e-12\n",
       "137   x2 x16 -7.810114e-12\n",
       "125    x2 x4 -7.369216e-12\n",
       "157   x2 x36 -7.226220e-12\n",
       "154   x2 x33 -7.027268e-12\n",
       "148   x2 x27 -6.579626e-12\n",
       "124    x2 x3 -5.348610e-12\n",
       "149   x2 x28 -2.117417e-12\n",
       "142   x2 x21 -2.083667e-12\n",
       "147   x2 x26 -2.040146e-12\n",
       "145   x2 x24 -1.811884e-12\n",
       "139   x2 x18 -1.397993e-12\n",
       "150   x2 x29 -6.252776e-13\n",
       "164    x3 x5 -4.405365e-13\n",
       "163    x3 x4 -3.694822e-13\n",
       "165    x3 x6 -6.616929e-14\n",
       "598  x16 x36  0.000000e+00\n",
       "637  x18 x28  0.000000e+00\n",
       "597  x16 x35  0.000000e+00\n",
       "638  x18 x29  0.000000e+00\n",
       "636  x18 x27  0.000000e+00\n",
       "629  x18 x20  0.000000e+00\n",
       "596  x16 x34  0.000000e+00\n",
       "640  x18 x31  0.000000e+00\n",
       "642  x18 x33  0.000000e+00\n",
       "643  x18 x34  0.000000e+00\n",
       "593  x16 x31  0.000000e+00\n",
       "646  x18 x37  0.000000e+00\n",
       "592  x16 x30  0.000000e+00\n",
       "647  x18 x38  0.000000e+00\n",
       "591  x16 x29  0.000000e+00\n",
       "639  x18 x30  0.000000e+00\n",
       "595  x16 x33  0.000000e+00\n",
       "604  x17 x18  0.000000e+00\n",
       "602  x16 x40  0.000000e+00\n",
       "626  x17 x40  0.000000e+00\n",
       "630  x18 x21  0.000000e+00\n",
       "631  x18 x22  0.000000e+00\n",
       "624  x17 x38  0.000000e+00\n",
       "632  x18 x23  0.000000e+00\n",
       "633  x18 x24  0.000000e+00\n",
       "620  x17 x34  0.000000e+00\n",
       "590  x16 x28  0.000000e+00\n",
       "619  x17 x33  0.000000e+00\n",
       "634  x18 x25  0.000000e+00\n",
       "617  x17 x31  0.000000e+00\n",
       "616  x17 x30  0.000000e+00\n",
       "615  x17 x29  0.000000e+00\n",
       "614  x17 x28  0.000000e+00\n",
       "613  x17 x27  0.000000e+00\n",
       "612  x17 x26  0.000000e+00\n",
       "611  x17 x25  0.000000e+00\n",
       "610  x17 x24  0.000000e+00\n",
       "609  x17 x23  0.000000e+00\n",
       "608  x17 x22  0.000000e+00\n",
       "607  x17 x21  0.000000e+00\n",
       "606  x17 x20  0.000000e+00\n",
       "635  x18 x26  0.000000e+00\n",
       "605  x17 x19  0.000000e+00\n",
       "628  x18 x19  0.000000e+00\n",
       "600  x16 x38  0.000000e+00\n",
       "207   x4 x11  0.000000e+00\n",
       "581  x16 x19  0.000000e+00\n",
       "588  x16 x26  0.000000e+00\n",
       "545  x14 x34  0.000000e+00\n",
       "544  x14 x33  0.000000e+00\n",
       "171   x3 x12  0.000000e+00\n",
       "542  x14 x31  0.000000e+00\n",
       "541  x14 x30  0.000000e+00\n",
       "540  x14 x29  0.000000e+00\n",
       "539  x14 x28  0.000000e+00\n",
       "538  x14 x27  0.000000e+00\n",
       "537  x14 x26  0.000000e+00\n",
       "536  x14 x25  0.000000e+00\n",
       "535  x14 x24  0.000000e+00\n",
       "534  x14 x23  0.000000e+00\n",
       "533  x14 x22  0.000000e+00\n",
       "532  x14 x21  0.000000e+00\n",
       "531  x14 x20  0.000000e+00\n",
       "530  x14 x19  0.000000e+00\n",
       "529  x14 x18  0.000000e+00\n",
       "512  x13 x28  0.000000e+00\n",
       "513  x13 x29  0.000000e+00\n",
       "514  x13 x30  0.000000e+00\n",
       "515  x13 x31  0.000000e+00\n",
       "517  x13 x33  0.000000e+00\n",
       "518  x13 x34  0.000000e+00\n",
       "170   x3 x11  0.000000e+00\n",
       "519  x13 x35  0.000000e+00\n",
       "522  x13 x38  0.000000e+00\n",
       "523  x13 x39  0.000000e+00\n",
       "172   x3 x13  0.000000e+00\n",
       "526  x14 x15  0.000000e+00\n",
       "527  x14 x16  0.000000e+00\n",
       "528  x14 x17  0.000000e+00\n",
       "520  x13 x36  0.000000e+00\n",
       "589  x16 x27  0.000000e+00\n",
       "169   x3 x10  0.000000e+00\n",
       "549  x14 x38  0.000000e+00\n",
       "587  x16 x25  0.000000e+00\n",
       "586  x16 x24  0.000000e+00\n",
       "585  x16 x23  0.000000e+00\n",
       "584  x16 x22  0.000000e+00\n",
       "583  x16 x21  0.000000e+00\n",
       "582  x16 x20  0.000000e+00\n",
       "580  x16 x18  0.000000e+00\n",
       "579  x16 x17  0.000000e+00\n",
       "576  x15 x39  0.000000e+00\n",
       "575  x15 x38  0.000000e+00\n",
       "573  x15 x36  0.000000e+00\n",
       "571  x15 x34  0.000000e+00\n",
       "570  x15 x33  0.000000e+00\n",
       "568  x15 x31  0.000000e+00\n",
       "567  x15 x30  0.000000e+00\n",
       "566  x15 x29  0.000000e+00\n",
       "565  x15 x28  0.000000e+00\n",
       "167    x3 x8  0.000000e+00\n",
       "551  x14 x40  0.000000e+00\n",
       "553  x15 x16  0.000000e+00\n",
       "206   x4 x10  0.000000e+00\n",
       "555  x15 x18  0.000000e+00\n",
       "556  x15 x19  0.000000e+00\n",
       "168    x3 x9  0.000000e+00\n",
       "557  x15 x20  0.000000e+00\n",
       "559  x15 x22  0.000000e+00\n",
       "560  x15 x23  0.000000e+00\n",
       "561  x15 x24  0.000000e+00\n",
       "562  x15 x25  0.000000e+00\n",
       "563  x15 x26  0.000000e+00\n",
       "564  x15 x27  0.000000e+00\n",
       "558  x15 x21  0.000000e+00\n",
       "651  x19 x20  0.000000e+00\n",
       "675  x20 x23  0.000000e+00\n",
       "653  x19 x22  0.000000e+00\n",
       "814  x28 x30  0.000000e+00\n",
       "813  x28 x29  0.000000e+00\n",
       "809  x27 x38  0.000000e+00\n",
       "805  x27 x34  0.000000e+00\n",
       "804  x27 x33  0.000000e+00\n",
       "801  x27 x30  0.000000e+00\n",
       "800  x27 x29  0.000000e+00\n",
       "799  x27 x28  0.000000e+00\n",
       "795  x26 x38  0.000000e+00\n",
       "791  x26 x34  0.000000e+00\n",
       "790  x26 x33  0.000000e+00\n",
       "788  x26 x31  0.000000e+00\n",
       "787  x26 x30  0.000000e+00\n",
       "786  x26 x29  0.000000e+00\n",
       "785  x26 x28  0.000000e+00\n",
       "784  x26 x27  0.000000e+00\n",
       "776  x25 x34  0.000000e+00\n",
       "775  x25 x33  0.000000e+00\n",
       "773  x25 x31  0.000000e+00\n",
       "772  x25 x30  0.000000e+00\n",
       "771  x25 x29  0.000000e+00\n",
       "770  x25 x28  0.000000e+00\n",
       "769  x25 x27  0.000000e+00\n",
       "768  x25 x26  0.000000e+00\n",
       "765  x24 x39  0.000000e+00\n",
       "764  x24 x38  0.000000e+00\n",
       "762  x24 x36  0.000000e+00\n",
       "760  x24 x34  0.000000e+00\n",
       "759  x24 x33  0.000000e+00\n",
       "815  x28 x31  0.000000e+00\n",
       "758  x24 x32  0.000000e+00\n",
       "818  x28 x34  0.000000e+00\n",
       "827  x29 x31  0.000000e+00\n",
       "894  x37 x38  0.000000e+00\n",
       "890  x36 x38  0.000000e+00\n",
       "889  x36 x37  0.000000e+00\n",
       "880  x34 x39  0.000000e+00\n",
       "879  x34 x38  0.000000e+00\n",
       "876  x34 x35  0.000000e+00\n",
       "874  x33 x40  0.000000e+00\n",
       "872  x33 x38  0.000000e+00\n",
       "871  x33 x37  0.000000e+00\n",
       "869  x33 x35  0.000000e+00\n",
       "868  x33 x34  0.000000e+00\n",
       "861  x32 x35  0.000000e+00\n",
       "860  x32 x34  0.000000e+00\n",
       "859  x32 x33  0.000000e+00\n",
       "856  x31 x39  0.000000e+00\n",
       "855  x31 x38  0.000000e+00\n",
       "852  x31 x35  0.000000e+00\n",
       "851  x31 x34  0.000000e+00\n",
       "850  x31 x33  0.000000e+00\n",
       "849  x31 x32  0.000000e+00\n",
       "847  x30 x40  0.000000e+00\n",
       "845  x30 x38  0.000000e+00\n",
       "842  x30 x35  0.000000e+00\n",
       "841  x30 x34  0.000000e+00\n",
       "840  x30 x33  0.000000e+00\n",
       "838  x30 x31  0.000000e+00\n",
       "834  x29 x38  0.000000e+00\n",
       "830  x29 x34  0.000000e+00\n",
       "829  x29 x33  0.000000e+00\n",
       "826  x29 x30  0.000000e+00\n",
       "652  x19 x21  0.000000e+00\n",
       "757  x24 x31  0.000000e+00\n",
       "755  x24 x29  0.000000e+00\n",
       "700  x21 x28  0.000000e+00\n",
       "699  x21 x27  0.000000e+00\n",
       "698  x21 x26  0.000000e+00\n",
       "697  x21 x25  0.000000e+00\n",
       "696  x21 x24  0.000000e+00\n",
       "695  x21 x23  0.000000e+00\n",
       "694  x21 x22  0.000000e+00\n",
       "685  x20 x33  0.000000e+00\n",
       "682  x20 x30  0.000000e+00\n",
       "681  x20 x29  0.000000e+00\n",
       "680  x20 x28  0.000000e+00\n",
       "679  x20 x27  0.000000e+00\n",
       "678  x20 x26  0.000000e+00\n",
       "677  x20 x25  0.000000e+00\n",
       "676  x20 x24  0.000000e+00\n",
       "511  x13 x27  0.000000e+00\n",
       "674  x20 x22  0.000000e+00\n",
       "673  x20 x21  0.000000e+00\n",
       "665  x19 x34  0.000000e+00\n",
       "664  x19 x33  0.000000e+00\n",
       "662  x19 x31  0.000000e+00\n",
       "661  x19 x30  0.000000e+00\n",
       "660  x19 x29  0.000000e+00\n",
       "659  x19 x28  0.000000e+00\n",
       "658  x19 x27  0.000000e+00\n",
       "657  x19 x26  0.000000e+00\n",
       "656  x19 x25  0.000000e+00\n",
       "655  x19 x24  0.000000e+00\n",
       "654  x19 x23  0.000000e+00\n",
       "701  x21 x29  0.000000e+00\n",
       "756  x24 x30  0.000000e+00\n",
       "702  x21 x30  0.000000e+00\n",
       "705  x21 x33  0.000000e+00\n",
       "754  x24 x28  0.000000e+00\n",
       "753  x24 x27  0.000000e+00\n",
       "752  x24 x26  0.000000e+00\n",
       "751  x24 x25  0.000000e+00\n",
       "747  x23 x38  0.000000e+00\n",
       "743  x23 x34  0.000000e+00\n",
       "742  x23 x33  0.000000e+00\n",
       "740  x23 x31  0.000000e+00\n",
       "739  x23 x30  0.000000e+00\n",
       "738  x23 x29  0.000000e+00\n",
       "737  x23 x28  0.000000e+00\n",
       "736  x23 x27  0.000000e+00\n",
       "735  x23 x26  0.000000e+00\n",
       "734  x23 x25  0.000000e+00\n",
       "733  x23 x24  0.000000e+00\n",
       "729  x22 x38  0.000000e+00\n",
       "725  x22 x34  0.000000e+00\n",
       "724  x22 x33  0.000000e+00\n",
       "722  x22 x31  0.000000e+00\n",
       "721  x22 x30  0.000000e+00\n",
       "720  x22 x29  0.000000e+00\n",
       "719  x22 x28  0.000000e+00\n",
       "718  x22 x27  0.000000e+00\n",
       "717  x22 x26  0.000000e+00\n",
       "716  x22 x25  0.000000e+00\n",
       "715  x22 x24  0.000000e+00\n",
       "714  x22 x23  0.000000e+00\n",
       "710  x21 x38  0.000000e+00\n",
       "706  x21 x34  0.000000e+00\n",
       "703  x21 x31  0.000000e+00\n",
       "510  x13 x26  0.000000e+00\n",
       "554  x15 x17  0.000000e+00\n",
       "508  x13 x24  0.000000e+00\n",
       "316   x7 x15  0.000000e+00\n",
       "317   x7 x16  0.000000e+00\n",
       "318   x7 x17  0.000000e+00\n",
       "319   x7 x18  0.000000e+00\n",
       "320   x7 x19  0.000000e+00\n",
       "321   x7 x20  0.000000e+00\n",
       "315   x7 x14  0.000000e+00\n",
       "322   x7 x21  0.000000e+00\n",
       "324   x7 x23  0.000000e+00\n",
       "325   x7 x24  0.000000e+00\n",
       "326   x7 x25  0.000000e+00\n",
       "327   x7 x26  0.000000e+00\n",
       "328   x7 x27  0.000000e+00\n",
       "329   x7 x28  0.000000e+00\n",
       "323   x7 x22  0.000000e+00\n",
       "330   x7 x29  0.000000e+00\n",
       "314   x7 x13  0.000000e+00\n",
       "312   x7 x11  0.000000e+00\n",
       "294   x6 x27  0.000000e+00\n",
       "295   x6 x28  0.000000e+00\n",
       "296   x6 x29  0.000000e+00\n",
       "297   x6 x30  0.000000e+00\n",
       "298   x6 x31  0.000000e+00\n",
       "299   x6 x32  0.000000e+00\n",
       "313   x7 x12  0.000000e+00\n",
       "300   x6 x33  0.000000e+00\n",
       "303   x6 x36  0.000000e+00\n",
       "305   x6 x38  0.000000e+00\n",
       "306   x6 x39  0.000000e+00\n",
       "309    x7 x8  0.000000e+00\n",
       "310    x7 x9  0.000000e+00\n",
       "311   x7 x10  0.000000e+00\n",
       "301   x6 x34  0.000000e+00\n",
       "293   x6 x26  0.000000e+00\n",
       "331   x7 x30  0.000000e+00\n",
       "333   x7 x32  0.000000e+00\n",
       "357   x8 x23  0.000000e+00\n",
       "358   x8 x24  0.000000e+00\n",
       "359   x8 x25  0.000000e+00\n",
       "360   x8 x26  0.000000e+00\n",
       "361   x8 x27  0.000000e+00\n",
       "362   x8 x28  0.000000e+00\n",
       "356   x8 x22  0.000000e+00\n",
       "363   x8 x29  0.000000e+00\n",
       "365   x8 x31  0.000000e+00\n",
       "202    x4 x6  0.000000e+00\n",
       "367   x8 x33  0.000000e+00\n",
       "368   x8 x34  0.000000e+00\n",
       "201    x4 x5  0.000000e+00\n",
       "199   x3 x40  0.000000e+00\n",
       "364   x8 x30  0.000000e+00\n",
       "332   x7 x31  0.000000e+00\n",
       "355   x8 x21  0.000000e+00\n",
       "353   x8 x19  0.000000e+00\n",
       "334   x7 x33  0.000000e+00\n",
       "509  x13 x25  0.000000e+00\n",
       "339   x7 x38  0.000000e+00\n",
       "203    x4 x7  0.000000e+00\n",
       "343    x8 x9  0.000000e+00\n",
       "344   x8 x10  0.000000e+00\n",
       "354   x8 x20  0.000000e+00\n",
       "345   x8 x11  0.000000e+00\n",
       "347   x8 x13  0.000000e+00\n",
       "348   x8 x14  0.000000e+00\n",
       "349   x8 x15  0.000000e+00\n",
       "350   x8 x16  0.000000e+00\n",
       "351   x8 x17  0.000000e+00\n",
       "352   x8 x18  0.000000e+00\n",
       "346   x8 x12  0.000000e+00\n",
       "292   x6 x25  0.000000e+00\n",
       "291   x6 x24  0.000000e+00\n",
       "290   x6 x23  0.000000e+00\n",
       "226   x4 x30  0.000000e+00\n",
       "227   x4 x31  0.000000e+00\n",
       "229   x4 x33  0.000000e+00\n",
       "230   x4 x34  0.000000e+00\n",
       "234   x4 x38  0.000000e+00\n",
       "236   x4 x40  0.000000e+00\n",
       "225   x4 x29  0.000000e+00\n",
       "238    x5 x6  0.000000e+00\n",
       "240    x5 x8  0.000000e+00\n",
       "241    x5 x9  0.000000e+00\n",
       "242   x5 x10  0.000000e+00\n",
       "243   x5 x11  0.000000e+00\n",
       "244   x5 x12  0.000000e+00\n",
       "245   x5 x13  0.000000e+00\n",
       "239    x5 x7  0.000000e+00\n",
       "246   x5 x14  0.000000e+00\n",
       "224   x4 x28  0.000000e+00\n",
       "222   x4 x26  0.000000e+00\n",
       "208   x4 x12  0.000000e+00\n",
       "209   x4 x13  0.000000e+00\n",
       "210   x4 x14  0.000000e+00\n",
       "211   x4 x15  0.000000e+00\n",
       "212   x4 x16  0.000000e+00\n",
       "213   x4 x17  0.000000e+00\n",
       "223   x4 x27  0.000000e+00\n",
       "214   x4 x18  0.000000e+00\n",
       "216   x4 x20  0.000000e+00\n",
       "217   x4 x21  0.000000e+00\n",
       "218   x4 x22  0.000000e+00\n",
       "219   x4 x23  0.000000e+00\n",
       "220   x4 x24  0.000000e+00\n",
       "221   x4 x25  0.000000e+00\n",
       "215   x4 x19  0.000000e+00\n",
       "247   x5 x15  0.000000e+00\n",
       "248   x5 x16  0.000000e+00\n",
       "249   x5 x17  0.000000e+00\n",
       "276    x6 x9  0.000000e+00\n",
       "277   x6 x10  0.000000e+00\n",
       "278   x6 x11  0.000000e+00\n",
       "279   x6 x12  0.000000e+00\n",
       "280   x6 x13  0.000000e+00\n",
       "281   x6 x14  0.000000e+00\n",
       "275    x6 x8  0.000000e+00\n",
       "282   x6 x15  0.000000e+00\n",
       "284   x6 x17  0.000000e+00\n",
       "285   x6 x18  0.000000e+00\n",
       "286   x6 x19  0.000000e+00\n",
       "287   x6 x20  0.000000e+00\n",
       "288   x6 x21  0.000000e+00\n",
       "289   x6 x22  0.000000e+00\n",
       "283   x6 x16  0.000000e+00\n",
       "274    x6 x7  0.000000e+00\n",
       "204    x4 x8  0.000000e+00\n",
       "270   x5 x38  0.000000e+00\n",
       "250   x5 x18  0.000000e+00\n",
       "251   x5 x19  0.000000e+00\n",
       "252   x5 x20  0.000000e+00\n",
       "253   x5 x21  0.000000e+00\n",
       "254   x5 x22  0.000000e+00\n",
       "255   x5 x23  0.000000e+00\n",
       "256   x5 x24  0.000000e+00\n",
       "257   x5 x25  0.000000e+00\n",
       "258   x5 x26  0.000000e+00\n",
       "259   x5 x27  0.000000e+00\n",
       "260   x5 x28  0.000000e+00\n",
       "261   x5 x29  0.000000e+00\n",
       "262   x5 x30  0.000000e+00\n",
       "265   x5 x33  0.000000e+00\n",
       "205    x4 x9  0.000000e+00\n",
       "372   x8 x38  0.000000e+00\n",
       "373   x8 x39  0.000000e+00\n",
       "335   x7 x34  0.000000e+00\n",
       "376   x9 x10  0.000000e+00\n",
       "448  x11 x21  0.000000e+00\n",
       "449  x11 x22  0.000000e+00\n",
       "450  x11 x23  0.000000e+00\n",
       "901  x39 x40  0.000000e+00\n",
       "452  x11 x25  0.000000e+00\n",
       "453  x11 x26  0.000000e+00\n",
       "454  x11 x27  0.000000e+00\n",
       "447  x11 x20  0.000000e+00\n",
       "197   x3 x38  0.000000e+00\n",
       "456  x11 x29  0.000000e+00\n",
       "457  x11 x30  0.000000e+00\n",
       "458  x11 x31  0.000000e+00\n",
       "460  x11 x33  0.000000e+00\n",
       "461  x11 x34  0.000000e+00\n",
       "185   x3 x26  0.000000e+00\n",
       "184   x3 x25  0.000000e+00\n",
       "455  x11 x28  0.000000e+00\n",
       "183   x3 x24  0.000000e+00\n",
       "446  x11 x19  0.000000e+00\n",
       "444  x11 x17  0.000000e+00\n",
       "426  x10 x29  0.000000e+00\n",
       "427  x10 x30  0.000000e+00\n",
       "428  x10 x31  0.000000e+00\n",
       "192   x3 x33  0.000000e+00\n",
       "430  x10 x33  0.000000e+00\n",
       "431  x10 x34  0.000000e+00\n",
       "190   x3 x31  0.000000e+00\n",
       "445  x11 x18  0.000000e+00\n",
       "189   x3 x30  0.000000e+00\n",
       "187   x3 x28  0.000000e+00\n",
       "186   x3 x27  0.000000e+00\n",
       "439  x11 x12  0.000000e+00\n",
       "440  x11 x13  0.000000e+00\n",
       "441  x11 x14  0.000000e+00\n",
       "442  x11 x15  0.000000e+00\n",
       "443  x11 x16  0.000000e+00\n",
       "188   x3 x29  0.000000e+00\n",
       "425  x10 x28  0.000000e+00\n",
       "182   x3 x23  0.000000e+00\n",
       "469  x12 x13  0.000000e+00\n",
       "178   x3 x19  0.000000e+00\n",
       "177   x3 x18  0.000000e+00\n",
       "176   x3 x17  0.000000e+00\n",
       "175   x3 x16  0.000000e+00\n",
       "174   x3 x15  0.000000e+00\n",
       "173   x3 x14  0.000000e+00\n",
       "498  x13 x14  0.000000e+00\n",
       "489  x12 x33  0.000000e+00\n",
       "499  x13 x15  0.000000e+00\n",
       "501  x13 x17  0.000000e+00\n",
       "502  x13 x18  0.000000e+00\n",
       "503  x13 x19  0.000000e+00\n",
       "504  x13 x20  0.000000e+00\n",
       "505  x13 x21  0.000000e+00\n",
       "506  x13 x22  0.000000e+00\n",
       "507  x13 x23  0.000000e+00\n",
       "500  x13 x16  0.000000e+00\n",
       "181   x3 x22  0.000000e+00\n",
       "179   x3 x20  0.000000e+00\n",
       "486  x12 x30  0.000000e+00\n",
       "470  x12 x14  0.000000e+00\n",
       "471  x12 x15  0.000000e+00\n",
       "472  x12 x16  0.000000e+00\n",
       "473  x12 x17  0.000000e+00\n",
       "474  x12 x18  0.000000e+00\n",
       "475  x12 x19  0.000000e+00\n",
       "476  x12 x20  0.000000e+00\n",
       "180   x3 x21  0.000000e+00\n",
       "477  x12 x21  0.000000e+00\n",
       "479  x12 x23  0.000000e+00\n",
       "480  x12 x24  0.000000e+00\n",
       "481  x12 x25  0.000000e+00\n",
       "482  x12 x26  0.000000e+00\n",
       "483  x12 x27  0.000000e+00\n",
       "484  x12 x28  0.000000e+00\n",
       "485  x12 x29  0.000000e+00\n",
       "478  x12 x22  0.000000e+00\n",
       "424  x10 x27  0.000000e+00\n",
       "451  x11 x24  0.000000e+00\n",
       "422  x10 x25  0.000000e+00\n",
       "379   x9 x13  0.000000e+00\n",
       "380   x9 x14  0.000000e+00\n",
       "381   x9 x15  0.000000e+00\n",
       "382   x9 x16  0.000000e+00\n",
       "383   x9 x17  0.000000e+00\n",
       "384   x9 x18  0.000000e+00\n",
       "385   x9 x19  0.000000e+00\n",
       "386   x9 x20  0.000000e+00\n",
       "387   x9 x21  0.000000e+00\n",
       "402   x9 x36  0.000000e+00\n",
       "388   x9 x22  0.000000e+00\n",
       "401   x9 x35  0.000000e+00\n",
       "400   x9 x34  0.000000e+00\n",
       "399   x9 x33  0.000000e+00\n",
       "397   x9 x31  0.000000e+00\n",
       "423  x10 x26  0.000000e+00\n",
       "396   x9 x30  0.000000e+00\n",
       "395   x9 x29  0.000000e+00\n",
       "394   x9 x28  0.000000e+00\n",
       "393   x9 x27  0.000000e+00\n",
       "392   x9 x26  0.000000e+00\n",
       "391   x9 x25  0.000000e+00\n",
       "389   x9 x23  0.000000e+00\n",
       "378   x9 x12  0.000000e+00\n",
       "404   x9 x38  0.000000e+00\n",
       "390   x9 x24  0.000000e+00\n",
       "413  x10 x16  0.000000e+00\n",
       "408  x10 x11  0.000000e+00\n",
       "193   x3 x34  0.000000e+00\n",
       "411  x10 x14  0.000000e+00\n",
       "412  x10 x15  0.000000e+00\n",
       "377   x9 x11  0.000000e+00\n",
       "414  x10 x17  0.000000e+00\n",
       "415  x10 x18  0.000000e+00\n",
       "409  x10 x12  0.000000e+00\n",
       "416  x10 x19  0.000000e+00\n",
       "417  x10 x20  0.000000e+00\n",
       "418  x10 x21  0.000000e+00\n",
       "419  x10 x22  0.000000e+00\n",
       "405   x9 x39  0.000000e+00\n",
       "420  x10 x23  0.000000e+00\n",
       "421  x10 x24  0.000000e+00\n",
       "410  x10 x13  0.000000e+00\n",
       "166    x3 x7  2.842171e-14\n",
       "129    x2 x8  2.631229e-13\n",
       "136   x2 x15  8.224532e-13\n",
       "83      x1^2  1.731060e-12\n",
       "152   x2 x31  3.957723e-12\n",
       "160   x2 x39  5.892176e-12\n",
       "144   x2 x23  7.987389e-12\n",
       "159   x2 x38  1.143263e-11\n",
       "135   x2 x14  1.640088e-11\n",
       "143   x2 x22  1.680345e-11\n",
       "130    x2 x9  1.734957e-11\n",
       "138   x2 x17  1.742184e-11\n",
       "141   x2 x20  2.060574e-11\n",
       "126    x2 x5  5.332357e-11\n",
       "128    x2 x7  6.334466e-11\n",
       "133   x2 x12  1.059544e-10\n",
       "43     x0 x1  7.189110e-09\n",
       "644  x18 x35  7.509676e-05\n",
       "648  x18 x39  7.509676e-05\n",
       "552    x15^2  7.261969e-04\n",
       "577  x15 x40  7.261969e-04\n",
       "574  x15 x37  7.261969e-04\n",
       "42      x0^2  8.566299e-04\n",
       "123     x2^2  1.097110e-03\n",
       "161   x2 x40  1.097110e-03\n",
       "158   x2 x37  1.097110e-03\n",
       "7         x6  1.951962e-03\n",
       "17       x16  1.344726e-02\n",
       "64    x0 x22  5.917567e-02\n",
       "25       x24  1.098767e-01\n",
       "843  x30 x36  1.709684e-01\n",
       "40       x39  2.416752e-01\n",
       "900    x39^2  2.416920e-01\n",
       "153   x2 x32  3.245489e-01\n",
       "844  x30 x37  3.520428e-01\n",
       "435  x10 x38  3.759362e-01\n",
       "264   x5 x32  4.793043e-01\n",
       "846  x30 x39  5.230111e-01\n",
       "839  x30 x32  5.230111e-01\n",
       "837    x30^2  5.230111e-01\n",
       "31       x30  5.458683e-01\n",
       "231   x4 x35  5.914063e-01\n",
       "569  x15 x32  6.286385e-01\n",
       "2         x1  6.945141e-01\n",
       "12       x11  8.577444e-01\n",
       "866  x32 x40  8.741461e-01\n",
       "438    x11^2  8.885128e-01\n",
       "683  x20 x31  9.198457e-01\n",
       "459  x11 x32  1.019306e+00\n",
       "233   x4 x37  1.043262e+00\n",
       "707  x21 x35  1.216998e+00\n",
       "232   x4 x36  1.286413e+00\n",
       "886  x35 x39  1.396778e+00\n",
       "708  x21 x36  1.610816e+00\n",
       "266   x5 x34  1.645894e+00\n",
       "228   x4 x32  1.738268e+00\n",
       "709  x21 x37  1.751295e+00\n",
       "269   x5 x37  1.934338e+00\n",
       "268   x5 x36  2.004459e+00\n",
       "704  x21 x32  2.145113e+00\n",
       "778  x25 x36  2.210622e+00\n",
       "779  x25 x37  2.232761e+00\n",
       "824  x28 x40  2.245415e+00\n",
       "836  x29 x40  2.274752e+00\n",
       "235   x4 x39  2.329675e+00\n",
       "200     x4^2  2.329675e+00\n",
       "5         x4  2.331478e+00\n",
       "792  x26 x35  2.541153e+00\n",
       "692  x20 x40  2.586266e+00\n",
       "263   x5 x31  2.713397e+00\n",
       "666  x19 x35  2.748913e+00\n",
       "494  x12 x38  2.918019e+00\n",
       "793  x26 x36  3.059073e+00\n",
       "794  x26 x37  3.100424e+00\n",
       "22       x21  3.269991e+00\n",
       "693    x21^2  3.362110e+00\n",
       "887  x35 x40  3.577056e+00\n",
       "789  x26 x32  3.618344e+00\n",
       "781  x25 x39  3.853097e+00\n",
       "6         x5  3.929690e+00\n",
       "237     x5^2  3.938797e+00\n",
       "663  x19 x32  4.176136e+00\n",
       "467  x11 x40  4.220585e+00\n",
       "882    x35^2  4.973834e+00\n",
       "36       x35  4.973836e+00\n",
       "822  x28 x38  5.091166e+00\n",
       "690  x20 x38  5.217565e+00\n",
       "712  x21 x40  5.328050e+00\n",
       "272   x5 x40  5.590977e+00\n",
       "27       x26  5.999575e+00\n",
       "465  x11 x38  6.028373e+00\n",
       "783    x26^2  6.159497e+00\n",
       "797  x26 x40  6.751793e+00\n",
       "777  x25 x35  6.776996e+00\n",
       "650    x19^2  6.925049e+00\n",
       "20       x19  6.969981e+00\n",
       "671  x19 x40  7.183262e+00\n",
       "774  x25 x32  8.403031e+00\n",
       "669  x19 x38  8.480914e+00\n",
       "780  x25 x38  1.073664e+01\n",
       "782  x25 x40  1.132693e+01\n",
       "340   x7 x39  1.296512e+01\n",
       "767    x25^2  1.518003e+01\n",
       "26       x25  1.520331e+01\n",
       "337   x7 x36  1.675313e+01\n",
       "338   x7 x37  1.680972e+01\n",
       "864  x32 x38  1.844352e+01\n",
       "899  x38 x40  1.932972e+01\n",
       "898  x38 x39  1.951890e+01\n",
       "885  x35 x38  2.040510e+01\n",
       "341   x7 x40  2.059774e+01\n",
       "336   x7 x35  3.356286e+01\n",
       "308     x7^2  3.356286e+01\n",
       "8         x7  3.362557e+01\n",
       "897    x38^2  3.884862e+01\n",
       "39       x38  3.884863e+01\n",
       "621  x17 x35  5.682463e+01\n",
       "622  x17 x36  5.698108e+01\n",
       "623  x17 x37  5.753457e+01\n",
       "618  x17 x32  5.769101e+01\n",
       "625  x17 x39  1.145156e+02\n",
       "603    x17^2  1.145156e+02\n",
       "18       x17  1.145637e+02"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importances.sort_values(by=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV\n",
    "\n",
    "To do cross-validation, we used two techniques:\n",
    "\n",
    "use KFolds and manually create a loop to do cross-validation\n",
    "use cross_val_predict and score to get a cross-valiated score in a couple of lines.\n",
    "To do hyper-parameter tuning, we see a general pattern:\n",
    "\n",
    "use cross_val_predict and score in a manually written loop over hyperparemeters, then select the best one.\n",
    "Perhaps not surprisingly, there is a function that does this for us -- GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same estimator as before\n",
    "estimator = Pipeline([(\"scaler\", StandardScaler()),\n",
    "        (\"polynomial_features\", PolynomialFeatures()),\n",
    "        (\"ridge_regression\", Ridge())])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3],\n",
    "    'ridge_regression__alpha': np.geomspace(4, 20, 30)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator, params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('polynomial_features',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('ridge_regression', Ridge())]),\n",
       "             param_grid={'polynomial_features__degree': [1, 2, 3],\n",
       "                         'ridge_regression__alpha': array([ 4.        ,  4.22826702,  4.46956049,  4.7246238 ,  4.99424274,\n",
       "        5.27924796,  5.58051751,  5.89897953,  6.23561514,  6.59146146,\n",
       "        6.96761476,  7.36523392,  7.78554391,  8.22983963,  8.69948987,\n",
       "        9.19594151,  9.72072404, 10.27545421, 10.86184103, 11.48169104,\n",
       "       12.13691388, 12.82952815, 13.56166768, 14.33558803, 15.15367351,\n",
       "       16.01844446, 16.93256509, 17.89885162, 18.92028098, 20.        ])})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8025878417677482,\n",
       " {'polynomial_features__degree': 2,\n",
       "  'ridge_regression__alpha': 20.000000000000004})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = grid.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8229145327162037"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This includes both in-sample and out-of-sample\n",
    "r2_score(y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  3.70594964e-01, -4.23534300e-02, -1.58860518e-06,\n",
       "        1.29565325e-03,  6.54606569e-04, -2.03931233e-03, -4.81906875e-06,\n",
       "       -1.82263551e-04, -1.16907042e-05,  3.61103575e-07,  6.16521020e-04,\n",
       "        2.81419580e-03,  5.33264963e-03,  4.05731733e-06,  6.14163191e-05,\n",
       "        2.21672512e-05,  2.33726234e-06,  7.87586715e-05,  1.20564996e-05,\n",
       "        4.33892758e-03, -6.81275618e-03,  8.60469490e-04,  2.89015103e-05,\n",
       "        8.61605989e-05,  1.46691078e-05,  1.42379550e-04,  4.45261320e-04,\n",
       "       -7.28719555e-03,  4.57068966e-03,  6.39134802e-04,  4.31077254e-05,\n",
       "       -1.82097621e-04,  7.68604162e-02, -2.52165665e-06, -6.21006711e-05,\n",
       "       -7.68321846e-02,  4.85883676e-03, -5.31938438e-03,  1.77804679e-03,\n",
       "        3.35676985e-03, -3.35676985e-03,  1.50370765e-02,  1.42989567e-03,\n",
       "       -2.93504242e-03,  6.86706838e-04, -5.52327860e-03, -1.19682360e-02,\n",
       "       -5.61338358e-03, -2.87666025e-02,  9.79114607e-03, -5.62598636e-03,\n",
       "        1.87204824e-02, -8.78593860e-03,  1.43910909e-02, -5.62133854e-03,\n",
       "       -6.14536145e-03, -8.54694788e-03, -5.62278743e-03, -2.76512925e-02,\n",
       "       -7.94047022e-03, -1.91936366e-02, -3.69000555e-03, -3.84993854e-03,\n",
       "        1.61396047e-03,  1.06334903e-02,  1.19997419e-02, -2.60328811e-02,\n",
       "       -9.19040257e-03,  4.19495852e-02, -1.79171762e-03, -1.97076479e-03,\n",
       "       -1.77222395e-02,  1.53353314e-03,  6.54620530e-03, -5.62182200e-03,\n",
       "        5.00308681e-04, -6.74267116e-03,  1.05455869e-02,  8.55483309e-03,\n",
       "       -5.37858494e-02,  2.57632275e-03, -2.57632275e-03,  3.76922339e-03,\n",
       "       -9.20438686e-03, -2.19141041e-03, -5.48623570e-03,  2.25670390e-03,\n",
       "        6.44650056e-04, -9.02838780e-03,  8.82067100e-04,  6.42752309e-04,\n",
       "        5.00103093e-03, -5.15900286e-03,  2.09347969e-03,  6.40693888e-04,\n",
       "       -3.34822263e-03,  4.23870380e-03,  6.40157310e-04, -1.56052434e-02,\n",
       "        8.87924740e-04, -7.32091144e-03, -6.31177838e-04, -1.31945260e-03,\n",
       "        9.00231662e-03,  3.96218763e-03, -2.34753119e-02,  4.70172212e-03,\n",
       "       -1.61695176e-03,  2.69621052e-03,  7.56498394e-03,  2.56210750e-03,\n",
       "       -6.36251777e-03, -1.65258032e-03,  7.32940853e-04,  6.43202457e-04,\n",
       "       -3.46263767e-03,  6.62205878e-05,  1.25895218e-03, -3.26330323e-03,\n",
       "        5.86676657e-03, -2.86679004e-03,  2.86679004e-03, -5.22552337e-05,\n",
       "       -3.91645731e-05, -1.97309849e-05,  6.22777393e-05,  1.70485670e-07,\n",
       "        5.68317075e-06,  5.02389491e-07,  1.31491412e-08, -1.83428381e-05,\n",
       "       -8.50806885e-05, -1.61200375e-04, -9.91153552e-08, -1.80627973e-06,\n",
       "       -6.31501012e-07, -4.68724067e-08, -2.33817243e-06, -3.32079744e-07,\n",
       "       -1.31304153e-04,  2.07950182e-04, -2.59916598e-05, -8.18712741e-07,\n",
       "       -2.42259067e-06, -4.11432066e-07, -4.02807087e-06, -1.33234231e-05,\n",
       "        2.21811303e-04, -1.38470191e-04, -1.91597660e-05, -1.26105347e-06,\n",
       "        5.68404004e-06, -6.36156090e-03,  1.00706746e-07,  2.00212839e-06,\n",
       "        6.36147786e-03, -1.46710800e-04,  1.60641414e-04, -5.37578713e-05,\n",
       "       -1.01415648e-04,  1.01415648e-04,  1.07895599e-02, -2.00883396e-04,\n",
       "       -3.42457308e-05, -1.90989487e-05, -9.85644170e-05, -1.18760337e-04,\n",
       "       -1.97122839e-05, -3.85086133e-04, -6.54889423e-04, -1.25721054e-03,\n",
       "       -2.01499177e-05, -5.54798201e-05, -3.67010930e-05, -1.99462622e-05,\n",
       "       -5.33277617e-05, -2.92476171e-05, -9.06346224e-04, -3.13447353e-05,\n",
       "       -2.18705185e-04, -5.16300487e-05, -1.68712653e-04, -2.95569513e-05,\n",
       "       -2.58599201e-04, -2.16185258e-04,  4.72546764e-04, -8.30398083e-04,\n",
       "       -2.81668851e-04, -4.44566434e-05, -1.03403436e-04, -1.63225691e-02,\n",
       "       -1.93709635e-05, -8.72190517e-05,  1.63589212e-02,  2.33864211e-03,\n",
       "       -2.11841032e-03, -4.11527439e-04,  3.42143821e-03, -3.42143821e-03,\n",
       "        6.81203358e-03,  5.48985731e-05, -9.47879981e-06, -4.33450476e-05,\n",
       "       -5.95877198e-05, -9.97207786e-06, -2.16385721e-04, -4.30506573e-04,\n",
       "       -8.23983345e-04, -1.03240471e-05, -3.02046353e-05, -1.93274158e-05,\n",
       "       -1.01602561e-05, -2.97313404e-05, -1.52037098e-05, -6.11533029e-04,\n",
       "        2.25365194e-04, -1.40961452e-04, -2.71084369e-05, -8.82896375e-05,\n",
       "       -1.54524935e-05, -1.35693672e-04, -1.24988104e-04,  4.96744972e-04,\n",
       "       -5.81366933e-04, -1.64936541e-04, -2.39871596e-05, -4.57957536e-05,\n",
       "       -4.97770243e-03, -9.69756917e-06, -4.18672918e-05,  4.99384751e-03,\n",
       "        4.37468083e-03, -4.13668661e-03, -2.70867866e-04,  1.60977850e-03,\n",
       "       -1.60977850e-03, -9.14976190e-03,  3.19845896e-05,  2.27886999e-04,\n",
       "        1.91590883e-04,  3.08823031e-05,  3.60028921e-04, -9.25073302e-05,\n",
       "       -1.49710547e-04,  3.00957876e-05,  6.28090828e-05,  4.89182109e-05,\n",
       "        3.04617972e-05,  5.24996571e-05,  4.12223881e-05, -3.05316581e-04,\n",
       "        2.76863221e-03,  7.79702885e-07,  6.97278936e-05,  2.31156926e-04,\n",
       "        4.06664524e-05,  3.50195498e-04,  1.62542859e-04,  2.16489628e-03,\n",
       "       -5.17363594e-04,  1.88227539e-04,  5.27668282e-05,  8.92650084e-03,\n",
       "       -4.78451789e-04,  3.14957243e-05,  5.72858288e-03, -2.06087377e-03,\n",
       "        1.11097685e-03, -1.05291295e-03, -6.19738664e-05,  4.93535026e-03,\n",
       "       -4.93535026e-03, -3.17364131e-04,  3.21384054e-06,  6.24345568e-07,\n",
       "        6.76771167e-08, -8.19871862e-06, -4.15262912e-05, -7.86281582e-05,\n",
       "        1.15642763e-08, -7.53065651e-07, -2.09780280e-07,  3.76767192e-08,\n",
       "       -1.03198444e-06, -7.95572397e-08, -6.44096904e-05,  1.06542382e-04,\n",
       "       -1.26284107e-05, -2.59452889e-07, -7.18450009e-07, -1.19219682e-07,\n",
       "       -1.26235193e-06, -6.15158900e-06,  1.12079680e-04, -6.83126555e-05,\n",
       "       -8.93663243e-06, -5.08056815e-07,  3.22924677e-06, -1.16204940e-03,\n",
       "        1.11440783e-07,  1.29451224e-06,  1.16147767e-03, -7.11362188e-05,\n",
       "        7.79533700e-05, -2.62452031e-05, -4.93246934e-05,  4.93246934e-05,\n",
       "       -1.94865135e-03,  1.79851681e-05,  2.73348877e-06, -1.32667027e-05,\n",
       "       -2.15704613e-04, -4.06454528e-04,  2.39074287e-06,  1.08651293e-06,\n",
       "        2.73809841e-06,  2.55024170e-06, -1.11321162e-06,  2.79555632e-06,\n",
       "       -3.47113719e-04,  7.49620583e-04, -6.33562532e-05,  4.10157595e-06,\n",
       "        1.43086805e-05,  2.55329199e-06,  2.08038068e-05, -1.82933223e-05,\n",
       "        7.30633010e-04, -3.83148803e-04, -3.02883334e-05,  1.53852842e-06,\n",
       "        3.44647731e-05, -6.94634195e-03,  3.00080400e-06,  1.90622365e-05,\n",
       "        6.93831040e-03, -2.09361278e-03,  2.07254575e-03, -1.36600258e-04,\n",
       "       -3.33932298e-03,  3.33932298e-03, -1.24989919e-04,  1.43993794e-07,\n",
       "       -5.43533353e-05, -2.58054741e-04, -4.88844024e-04, -1.98752104e-07,\n",
       "       -5.26008622e-06, -1.74807249e-06, -3.92532722e-08, -6.90616921e-06,\n",
       "       -8.66964669e-07, -3.98801485e-04,  6.39300604e-04, -7.87362889e-05,\n",
       "       -2.24502321e-06, -6.55932953e-06, -1.10922900e-06, -1.10214644e-05,\n",
       "       -3.98136426e-05,  6.79255089e-04, -4.21225413e-04, -5.74075820e-05,\n",
       "       -3.64225284e-06,  1.80132668e-05, -9.55506057e-03,  4.11309029e-07,\n",
       "        6.61185121e-06,  9.55259297e-03,  2.38599761e-03, -2.25084820e-03,\n",
       "       -1.63062675e-04, -3.07303263e-04,  3.07303263e-04,  2.37808034e-05,\n",
       "       -9.44648954e-06, -4.28124335e-05, -8.11302668e-05, -6.70767884e-08,\n",
       "       -9.45807217e-07, -3.46022002e-07, -4.09643456e-08, -1.20791231e-06,\n",
       "       -1.90785317e-07, -6.59794100e-05,  1.03192045e-04, -1.30954912e-05,\n",
       "       -4.52194455e-07, -1.35219618e-06, -2.30447760e-07, -2.22886208e-06,\n",
       "       -6.80514535e-06,  1.10519370e-04, -6.94690142e-05, -9.76022414e-06,\n",
       "       -6.65393343e-07,  2.72962658e-06, -1.16646692e-03,  3.27997181e-08,\n",
       "        9.16403166e-07,  1.16604891e-03, -7.39596319e-05,  8.09643582e-05,\n",
       "       -2.70488473e-05, -5.10821993e-05,  5.10821993e-05,  2.41100827e-03,\n",
       "       -8.30938660e-04, -1.58228860e-03, -1.03368128e-05, -3.77328610e-05,\n",
       "       -2.15544058e-05, -9.92249561e-06, -3.99090995e-05, -1.61419722e-05,\n",
       "       -1.23195761e-03,  1.24227641e-03, -2.62854903e-04, -2.99008759e-05,\n",
       "       -9.61795268e-05, -1.67712826e-05, -1.49325320e-04, -1.85035419e-04,\n",
       "        1.56959776e-03, -1.23858680e-03, -2.51971427e-04, -2.91090400e-05,\n",
       "       -1.55999117e-05, -4.70863448e-03, -8.75210639e-06, -3.00423947e-05,\n",
       "        4.71720613e-03,  5.27814298e-03,  1.11389058e-03, -1.78350635e-02,\n",
       "        1.44031735e-02, -1.44031735e-02,  1.06359722e-02, -2.68330261e-03,\n",
       "       -4.37301360e-05, -1.19957907e-04, -7.95188066e-05, -4.33030777e-05,\n",
       "       -1.15129442e-04, -6.34195047e-05, -1.93004712e-03, -1.28630825e-04,\n",
       "       -4.67386375e-04, -1.11885072e-04, -3.65682930e-04, -6.40681677e-05,\n",
       "       -5.60419424e-04, -4.65603233e-04,  9.61619246e-04, -1.76302578e-03,\n",
       "       -6.06112391e-04, -9.61779724e-05, -2.26213626e-04, -1.14956642e-02,\n",
       "       -4.20966967e-05, -1.89994194e-04,  1.15701262e-02,  9.37833263e-04,\n",
       "        2.77557968e-03, -1.05614704e-02, -4.99425769e-03,  4.99425769e-03,\n",
       "        8.46454822e-03, -8.29155989e-05, -2.28079966e-04, -1.50959116e-04,\n",
       "       -8.20847840e-05, -2.19148012e-04, -1.20325541e-04, -3.71169745e-03,\n",
       "       -1.58279880e-04, -8.96449765e-04, -2.12374778e-04, -6.94017344e-04,\n",
       "       -1.21587474e-04, -1.06373085e-03, -8.87862205e-04,  1.91359831e-03,\n",
       "       -3.39811432e-03, -1.15654659e-03, -1.82789439e-04, -1.61762807e-03,\n",
       "        4.32855041e-03, -7.97378461e-05,  1.29109644e-03, -4.20530325e-03,\n",
       "       -3.63062833e-03,  1.55110252e-03,  5.62222888e-03, -1.60402268e-03,\n",
       "        1.60402268e-03,  2.67198304e-04, -1.08333431e-06, -4.43234699e-07,\n",
       "       -9.70771862e-08, -1.33344231e-06, -2.70150003e-07, -6.70994536e-05,\n",
       "        1.00801476e-04, -1.34287675e-05, -5.89721545e-07, -1.80439374e-06,\n",
       "       -3.09812446e-07, -2.91849707e-06, -7.27147809e-06,  1.09406040e-04,\n",
       "       -7.02941120e-05, -1.03478824e-05, -7.77657840e-07,  2.37313207e-06,\n",
       "       -1.16274163e-03, -2.33131224e-08,  6.46610604e-07,  1.16243190e-03,\n",
       "       -7.59742248e-05,  8.31127918e-05, -2.76222724e-05, -5.23362343e-05,\n",
       "        5.23362343e-05,  1.64835579e-03, -2.44007630e-06, -1.01933526e-06,\n",
       "       -5.01622542e-06, -1.76731721e-06, -1.80051556e-04,  2.13764302e-04,\n",
       "       -3.75536918e-05, -3.36050591e-06, -1.07195441e-05, -1.86452598e-06,\n",
       "       -1.67565764e-05, -2.43156754e-05,  2.52639662e-04, -1.83774035e-04,\n",
       "       -3.35451798e-05, -3.46932105e-06,  8.51892042e-07, -6.47771345e-03,\n",
       "       -8.38546748e-07, -2.17226116e-06,  6.47921266e-03, -1.29594197e-03,\n",
       "        1.27980852e-03, -7.56848157e-05,  5.61247207e-05, -5.61247207e-05,\n",
       "        8.42258516e-04, -3.97996194e-07, -2.82424087e-06, -7.93066086e-07,\n",
       "       -1.20833689e-04,  1.64842754e-04, -2.46296311e-05, -1.58491681e-06,\n",
       "       -4.97803494e-06, -8.61779290e-07, -7.88060819e-06, -1.45073778e-05,\n",
       "        1.84980775e-04, -1.25160300e-04, -2.03339934e-05, -1.80704202e-06,\n",
       "        2.65128001e-06, -1.77194972e-03, -2.70203633e-07,  1.52627222e-08,\n",
       "        1.77181026e-03, -1.39872489e-04,  1.52787855e-04, -5.02027196e-05,\n",
       "       -9.58059208e-05,  9.58059208e-05,  1.53922528e-04, -1.27502619e-06,\n",
       "       -2.33217175e-07, -6.65782347e-05,  1.01913942e-04, -1.32736754e-05,\n",
       "       -5.25722499e-07, -1.59396092e-06, -2.72879619e-07, -2.59757134e-06,\n",
       "       -7.05446739e-06,  1.09924135e-04, -6.99101479e-05, -1.00744121e-05,\n",
       "       -7.25414891e-07,  2.53902890e-06, -1.16447521e-03,  2.79932044e-09,\n",
       "        7.72160172e-07,  1.16411510e-03, -7.50367221e-05,  8.21130055e-05,\n",
       "       -2.73554257e-05, -4.40707066e-05,  4.40707066e-05,  2.31636357e-03,\n",
       "       -2.10055753e-06, -1.71223520e-04,  1.80435241e-04, -3.63245062e-05,\n",
       "       -3.91196462e-06, -1.25615623e-05, -2.18928636e-06, -1.95301587e-05,\n",
       "       -2.50584537e-05,  2.23763387e-04, -1.72809888e-04, -3.42279378e-05,\n",
       "       -3.85613940e-06, -1.41180138e-06, -4.24441660e-03, -1.11000864e-06,\n",
       "       -3.63967222e-06,  4.24611445e-03, -2.78898802e-03,  2.72278908e-03,\n",
       "       -7.26041375e-05,  1.18135880e-04, -1.18135880e-04,  5.61242743e-04,\n",
       "       -9.68183807e-05,  1.38485053e-04, -1.95630021e-05, -1.06916289e-06,\n",
       "       -3.32503189e-06, -5.73849236e-07, -5.30664450e-06, -1.10817091e-05,\n",
       "        1.52838328e-04, -1.00832681e-04, -1.56402844e-05, -1.29179432e-06,\n",
       "        2.74714756e-06, -1.45197297e-03, -1.28887014e-07,  4.53395409e-07,\n",
       "        1.45168199e-03, -8.22080965e-05,  9.34749486e-05, -4.00484480e-05,\n",
       "       -3.82174905e-04,  3.82174905e-04,  1.30039294e-02, -7.41819413e-04,\n",
       "       -6.51971335e-04, -1.70198769e-04, -5.56936434e-04, -9.76100653e-05,\n",
       "       -8.52696254e-04, -6.82345852e-04,  9.01279327e-04, -2.35360081e-03,\n",
       "       -8.83516390e-04, -1.44848240e-04, -3.63303280e-04,  5.60542828e-03,\n",
       "       -6.51058628e-05, -2.97887243e-04, -5.49187792e-03,  3.67638689e-03,\n",
       "       -8.09942223e-03,  1.30308210e-02, -1.20377997e-03,  1.20377997e-03,\n",
       "       -6.12741296e-03,  5.77668561e-05,  2.34793634e-04,  7.77752329e-04,\n",
       "        1.36795318e-04,  1.17903000e-03,  5.71553316e-04,  6.76513602e-03,\n",
       "       -1.43534996e-03,  6.69787091e-04,  1.79042309e-04, -8.98003303e-04,\n",
       "        1.16347592e-02,  1.05056504e-04, -3.50112602e-03, -1.09601395e-02,\n",
       "        4.85898865e-03, -6.43186546e-03,  4.96811827e-03, -7.44215393e-03,\n",
       "        7.44215393e-03,  9.46548237e-03, -3.46219302e-05, -1.13039322e-04,\n",
       "       -1.97985730e-05, -1.73383267e-04, -1.48708980e-04,  3.97883924e-04,\n",
       "       -6.04205961e-04, -1.94434241e-04, -3.00217922e-05, -6.65718575e-05,\n",
       "       -9.75202342e-03, -1.28355614e-05, -5.72076173e-05,  9.77543720e-03,\n",
       "       -3.81036941e-03,  3.78778842e-03, -2.93813032e-04,  7.49717964e-04,\n",
       "       -7.49717964e-04,  7.75689141e-04, -6.74165796e-06, -1.16637166e-06,\n",
       "       -1.06900035e-05, -2.02134451e-05,  2.62433385e-04, -1.76515824e-04,\n",
       "       -2.83756748e-05, -2.48175407e-06,  3.98789867e-06, -1.03646714e-03,\n",
       "       -3.44933987e-07,  2.01046812e-07,  1.03589745e-03, -2.23301770e-03,\n",
       "        2.18437712e-03, -7.06405168e-05, -3.08312728e-03,  3.08312728e-03,\n",
       "        6.93726423e-04, -3.64466033e-06, -3.34945591e-05, -6.53440544e-05,\n",
       "        8.65568700e-04, -5.78415047e-04, -9.18908399e-05, -7.89077327e-06,\n",
       "        1.39678934e-05, -1.79448650e-03, -9.99517131e-07,  1.30844256e-06,\n",
       "        1.79202262e-03, -5.41464767e-04,  6.04207407e-04, -2.30894404e-04,\n",
       "       -1.57314188e-03,  1.57314188e-03,  6.82862402e-04, -5.79410171e-06,\n",
       "       -1.14113287e-05,  1.52051390e-04, -1.01415888e-04, -1.60556610e-05,\n",
       "       -1.37114665e-06,  2.49516525e-06, -1.66489285e-03, -1.68549458e-07,\n",
       "        2.62696958e-07,  1.66472237e-03, -1.12323681e-04,  1.22743679e-04,\n",
       "       -4.04537642e-05, -7.70530546e-05,  7.70530546e-05,  7.36541937e-04,\n",
       "       -1.01039621e-04,  1.31675008e-03, -8.84576714e-04, -1.41885800e-04,\n",
       "       -1.23674570e-05,  2.02432460e-05,  1.19002575e-02, -1.69100024e-06,\n",
       "        1.19415511e-06, -1.19066764e-02, -1.44761278e-03,  4.92403151e-03,\n",
       "       -1.01062743e-02, -1.93003883e-03,  1.93003883e-03,  3.47302251e-03,\n",
       "        7.85272594e-04, -6.76055711e-04, -1.51428194e-04, -1.89625349e-05,\n",
       "       -1.99704718e-05, -8.94368941e-03, -6.44144196e-06, -2.46654068e-05,\n",
       "        8.95310914e-03, -2.59513171e-03,  2.61228381e-03, -2.93404420e-04,\n",
       "        1.01669605e-03, -1.01669605e-03, -2.19982643e-02,  2.49976287e-04,\n",
       "        9.66073167e-04,  2.08348407e-04, -1.85666163e-03,  4.30139493e-03,\n",
       "        1.11387680e-04,  5.50609300e-04, -4.03069959e-03, -5.03902599e-03,\n",
       "        4.66622526e-03,  5.94962568e-04,  9.36538567e-04, -9.36538567e-04,\n",
       "        1.94551403e-02, -8.69363198e-04, -1.48447657e-04, -4.00187196e-04,\n",
       "        2.82646868e-03, -8.06847411e-05, -3.19759360e-04, -2.70165090e-03,\n",
       "       -7.67619282e-03,  6.79482930e-03,  1.80530411e-03,  7.75569183e-03,\n",
       "       -7.75569183e-03,  3.91837202e-03, -2.62660020e-05, -3.26920704e-05,\n",
       "       -1.07783867e-02, -9.30189626e-06, -3.67781339e-05,  1.07924587e-02,\n",
       "        1.27252797e-03, -1.09762852e-03, -3.81844741e-04, -2.66495715e-03,\n",
       "        2.66495715e-03,  1.41797614e-03,  1.37314313e-06, -2.29102212e-03,\n",
       "       -5.77835739e-07, -1.26032836e-06,  2.29142746e-03, -3.81609072e-03,\n",
       "        3.71203588e-03, -6.06919933e-05,  2.51035231e-05, -2.51035231e-05,\n",
       "       -1.87046526e-03, -7.23240021e-03,  3.00766467e-06,  1.92811176e-05,\n",
       "        7.58854928e-03,  2.03619287e-03, -1.91943360e-03, -1.43239707e-04,\n",
       "       -2.61974359e-04,  2.61974359e-04,  1.20430154e-03, -1.16432888e-03,\n",
       "       -5.54854882e-03,  1.01927153e-03,  1.70182416e-04,  3.56900068e-03,\n",
       "       -1.07076162e-02,  5.51914795e-03, -5.51914795e-03, -1.66065977e-04,\n",
       "        1.12682045e-06,  1.16886989e-03, -7.83893489e-05,  8.50927810e-05,\n",
       "       -2.66016202e-05, -5.83921589e-05,  5.83921589e-05, -8.46259176e-04,\n",
       "        5.66887410e-03,  4.79958845e-03, -4.60020561e-03, -1.20148277e-04,\n",
       "       -2.23946767e-04,  2.23946767e-04, -3.32899537e-03, -1.25419370e-03,\n",
       "       -2.53723478e-03,  1.07554408e-02, -5.43589368e-03,  5.43589368e-03,\n",
       "        6.26633293e-03, -5.45996310e-03, -1.72290343e-03, -2.42078250e-03,\n",
       "        2.42078250e-03,  6.05968364e-03, -2.23375057e-03,  2.01155072e-03,\n",
       "       -2.01155072e-03,  1.11851845e-02,  9.45832135e-04, -9.45832135e-04,\n",
       "        8.75506321e-03, -8.75506321e-03,  8.75506321e-03])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that \"grid\" is a fit object!\n",
    "# We can use grid.predict(X_test) to get brand new predictions!\n",
    "grid.best_estimator_.named_steps['ridge_regression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_polynomial_features__degree</th>\n",
       "      <th>param_ridge_regression__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782295</td>\n",
       "      <td>0.784909</td>\n",
       "      <td>0.797389</td>\n",
       "      <td>0.788198</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014285</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1</td>\n",
       "      <td>4.228267</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782296</td>\n",
       "      <td>0.784907</td>\n",
       "      <td>0.797391</td>\n",
       "      <td>0.788198</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013519</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1</td>\n",
       "      <td>4.46956</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782297</td>\n",
       "      <td>0.784905</td>\n",
       "      <td>0.797393</td>\n",
       "      <td>0.788198</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013020</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1</td>\n",
       "      <td>4.724624</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782298</td>\n",
       "      <td>0.784902</td>\n",
       "      <td>0.797395</td>\n",
       "      <td>0.788198</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1</td>\n",
       "      <td>4.994243</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782299</td>\n",
       "      <td>0.784899</td>\n",
       "      <td>0.797398</td>\n",
       "      <td>0.788199</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012979</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1</td>\n",
       "      <td>5.279248</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782300</td>\n",
       "      <td>0.784896</td>\n",
       "      <td>0.797400</td>\n",
       "      <td>0.788199</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013046</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>5.580518</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782302</td>\n",
       "      <td>0.784893</td>\n",
       "      <td>0.797403</td>\n",
       "      <td>0.788199</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>1</td>\n",
       "      <td>5.89898</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782303</td>\n",
       "      <td>0.784890</td>\n",
       "      <td>0.797405</td>\n",
       "      <td>0.788199</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1</td>\n",
       "      <td>6.235615</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782304</td>\n",
       "      <td>0.784887</td>\n",
       "      <td>0.797408</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013251</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1</td>\n",
       "      <td>6.591461</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782306</td>\n",
       "      <td>0.784883</td>\n",
       "      <td>0.797411</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.013765</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1</td>\n",
       "      <td>6.967615</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782307</td>\n",
       "      <td>0.784879</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1</td>\n",
       "      <td>7.365234</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782309</td>\n",
       "      <td>0.784875</td>\n",
       "      <td>0.797417</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.013505</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1</td>\n",
       "      <td>7.785544</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782311</td>\n",
       "      <td>0.784871</td>\n",
       "      <td>0.797421</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1</td>\n",
       "      <td>8.22984</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782312</td>\n",
       "      <td>0.784866</td>\n",
       "      <td>0.797424</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1</td>\n",
       "      <td>8.69949</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782314</td>\n",
       "      <td>0.784861</td>\n",
       "      <td>0.797428</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013317</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1</td>\n",
       "      <td>9.195942</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782316</td>\n",
       "      <td>0.784856</td>\n",
       "      <td>0.797432</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013247</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1</td>\n",
       "      <td>9.720724</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782318</td>\n",
       "      <td>0.784851</td>\n",
       "      <td>0.797436</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1</td>\n",
       "      <td>10.275454</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782320</td>\n",
       "      <td>0.784845</td>\n",
       "      <td>0.797440</td>\n",
       "      <td>0.788202</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013320</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>1</td>\n",
       "      <td>10.861841</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782322</td>\n",
       "      <td>0.784838</td>\n",
       "      <td>0.797445</td>\n",
       "      <td>0.788202</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013911</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1</td>\n",
       "      <td>11.481691</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782324</td>\n",
       "      <td>0.784832</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>0.788202</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1</td>\n",
       "      <td>12.136914</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782326</td>\n",
       "      <td>0.784825</td>\n",
       "      <td>0.797454</td>\n",
       "      <td>0.788202</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1</td>\n",
       "      <td>12.829528</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782328</td>\n",
       "      <td>0.784817</td>\n",
       "      <td>0.797459</td>\n",
       "      <td>0.788202</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1</td>\n",
       "      <td>13.561668</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782331</td>\n",
       "      <td>0.784809</td>\n",
       "      <td>0.797465</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1</td>\n",
       "      <td>14.335588</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>0.797470</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1</td>\n",
       "      <td>15.153674</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782335</td>\n",
       "      <td>0.784791</td>\n",
       "      <td>0.797476</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1</td>\n",
       "      <td>16.018444</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782338</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>0.797482</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1</td>\n",
       "      <td>16.932565</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782340</td>\n",
       "      <td>0.784771</td>\n",
       "      <td>0.797488</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1</td>\n",
       "      <td>17.898852</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782343</td>\n",
       "      <td>0.784760</td>\n",
       "      <td>0.797494</td>\n",
       "      <td>0.788199</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "      <td>18.920281</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782345</td>\n",
       "      <td>0.784748</td>\n",
       "      <td>0.797501</td>\n",
       "      <td>0.788198</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'polynomial_features__degree': 1, 'ridge_regr...</td>\n",
       "      <td>0.782348</td>\n",
       "      <td>0.784735</td>\n",
       "      <td>0.797508</td>\n",
       "      <td>0.788197</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.131188</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.016158</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784198</td>\n",
       "      <td>0.806143</td>\n",
       "      <td>0.815954</td>\n",
       "      <td>0.802098</td>\n",
       "      <td>0.013276</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.123715</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>2</td>\n",
       "      <td>4.228267</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784209</td>\n",
       "      <td>0.806145</td>\n",
       "      <td>0.815972</td>\n",
       "      <td>0.802108</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.124478</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.016280</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>2</td>\n",
       "      <td>4.46956</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784220</td>\n",
       "      <td>0.806146</td>\n",
       "      <td>0.815990</td>\n",
       "      <td>0.802119</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.140053</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2</td>\n",
       "      <td>4.724624</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784232</td>\n",
       "      <td>0.806148</td>\n",
       "      <td>0.816009</td>\n",
       "      <td>0.802130</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.124167</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.016040</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>2</td>\n",
       "      <td>4.994243</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784244</td>\n",
       "      <td>0.806150</td>\n",
       "      <td>0.816029</td>\n",
       "      <td>0.802141</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.126594</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>2</td>\n",
       "      <td>5.279248</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784257</td>\n",
       "      <td>0.806152</td>\n",
       "      <td>0.816049</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.130767</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>2</td>\n",
       "      <td>5.580518</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784271</td>\n",
       "      <td>0.806154</td>\n",
       "      <td>0.816070</td>\n",
       "      <td>0.802165</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.123524</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.015943</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>2</td>\n",
       "      <td>5.89898</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784285</td>\n",
       "      <td>0.806156</td>\n",
       "      <td>0.816091</td>\n",
       "      <td>0.802178</td>\n",
       "      <td>0.013286</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.124602</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2</td>\n",
       "      <td>6.235615</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784301</td>\n",
       "      <td>0.806158</td>\n",
       "      <td>0.816113</td>\n",
       "      <td>0.802191</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.132031</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2</td>\n",
       "      <td>6.591461</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784317</td>\n",
       "      <td>0.806161</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.802204</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.125439</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>2</td>\n",
       "      <td>6.967615</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784334</td>\n",
       "      <td>0.806163</td>\n",
       "      <td>0.816159</td>\n",
       "      <td>0.802219</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.125390</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.016277</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>2</td>\n",
       "      <td>7.365234</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784351</td>\n",
       "      <td>0.806165</td>\n",
       "      <td>0.816183</td>\n",
       "      <td>0.802233</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.122423</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.015874</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>2</td>\n",
       "      <td>7.785544</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784370</td>\n",
       "      <td>0.806167</td>\n",
       "      <td>0.816208</td>\n",
       "      <td>0.802248</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.017996</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>2</td>\n",
       "      <td>8.22984</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784390</td>\n",
       "      <td>0.806170</td>\n",
       "      <td>0.816233</td>\n",
       "      <td>0.802264</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.124015</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>2</td>\n",
       "      <td>8.69949</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784410</td>\n",
       "      <td>0.806172</td>\n",
       "      <td>0.816259</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.121034</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>2</td>\n",
       "      <td>9.195942</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784432</td>\n",
       "      <td>0.806175</td>\n",
       "      <td>0.816285</td>\n",
       "      <td>0.802297</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.134903</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>2</td>\n",
       "      <td>9.720724</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784455</td>\n",
       "      <td>0.806177</td>\n",
       "      <td>0.816312</td>\n",
       "      <td>0.802315</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.120816</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.015881</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>2</td>\n",
       "      <td>10.275454</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784479</td>\n",
       "      <td>0.806179</td>\n",
       "      <td>0.816339</td>\n",
       "      <td>0.802333</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.123184</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>2</td>\n",
       "      <td>10.861841</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784504</td>\n",
       "      <td>0.806182</td>\n",
       "      <td>0.816367</td>\n",
       "      <td>0.802351</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.120703</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>2</td>\n",
       "      <td>11.481691</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784531</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.816395</td>\n",
       "      <td>0.802370</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.122317</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>2</td>\n",
       "      <td>12.136914</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784558</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>0.816424</td>\n",
       "      <td>0.802389</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.149985</td>\n",
       "      <td>0.024305</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>2</td>\n",
       "      <td>12.829528</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784587</td>\n",
       "      <td>0.806188</td>\n",
       "      <td>0.816453</td>\n",
       "      <td>0.802410</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.123631</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>2</td>\n",
       "      <td>13.561668</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784618</td>\n",
       "      <td>0.806190</td>\n",
       "      <td>0.816483</td>\n",
       "      <td>0.802430</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.126974</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>2</td>\n",
       "      <td>14.335588</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784649</td>\n",
       "      <td>0.806192</td>\n",
       "      <td>0.816512</td>\n",
       "      <td>0.802451</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.147489</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.016348</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>2</td>\n",
       "      <td>15.153674</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784683</td>\n",
       "      <td>0.806194</td>\n",
       "      <td>0.816542</td>\n",
       "      <td>0.802473</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.123858</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>2</td>\n",
       "      <td>16.018444</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784717</td>\n",
       "      <td>0.806195</td>\n",
       "      <td>0.816572</td>\n",
       "      <td>0.802495</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.122233</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>2</td>\n",
       "      <td>16.932565</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784754</td>\n",
       "      <td>0.806196</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.802517</td>\n",
       "      <td>0.013260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.125739</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.015912</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2</td>\n",
       "      <td>17.898852</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784792</td>\n",
       "      <td>0.806197</td>\n",
       "      <td>0.816633</td>\n",
       "      <td>0.802541</td>\n",
       "      <td>0.013254</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.122161</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>2</td>\n",
       "      <td>18.920281</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784831</td>\n",
       "      <td>0.806197</td>\n",
       "      <td>0.816664</td>\n",
       "      <td>0.802564</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.122870</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'polynomial_features__degree': 2, 'ridge_regr...</td>\n",
       "      <td>0.784873</td>\n",
       "      <td>0.806197</td>\n",
       "      <td>0.816694</td>\n",
       "      <td>0.802588</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.677843</td>\n",
       "      <td>0.186299</td>\n",
       "      <td>0.158307</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.693430</td>\n",
       "      <td>0.709088</td>\n",
       "      <td>0.791751</td>\n",
       "      <td>0.731423</td>\n",
       "      <td>0.043135</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2.573720</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.158314</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>3</td>\n",
       "      <td>4.228267</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.695435</td>\n",
       "      <td>0.710707</td>\n",
       "      <td>0.792029</td>\n",
       "      <td>0.732724</td>\n",
       "      <td>0.042396</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2.643627</td>\n",
       "      <td>0.042948</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>3</td>\n",
       "      <td>4.46956</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.697434</td>\n",
       "      <td>0.712311</td>\n",
       "      <td>0.792309</td>\n",
       "      <td>0.734018</td>\n",
       "      <td>0.041663</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2.641217</td>\n",
       "      <td>0.123821</td>\n",
       "      <td>0.155143</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>3</td>\n",
       "      <td>4.724624</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.713901</td>\n",
       "      <td>0.792592</td>\n",
       "      <td>0.735305</td>\n",
       "      <td>0.040937</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2.563514</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.154237</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>3</td>\n",
       "      <td>4.994243</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.701397</td>\n",
       "      <td>0.715475</td>\n",
       "      <td>0.792877</td>\n",
       "      <td>0.736583</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2.603444</td>\n",
       "      <td>0.078869</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>3</td>\n",
       "      <td>5.279248</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.703356</td>\n",
       "      <td>0.717033</td>\n",
       "      <td>0.793165</td>\n",
       "      <td>0.737852</td>\n",
       "      <td>0.039509</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2.571187</td>\n",
       "      <td>0.050437</td>\n",
       "      <td>0.154642</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>3</td>\n",
       "      <td>5.580518</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.705297</td>\n",
       "      <td>0.718573</td>\n",
       "      <td>0.793456</td>\n",
       "      <td>0.739109</td>\n",
       "      <td>0.038810</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.527269</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.152877</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>3</td>\n",
       "      <td>5.89898</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.707217</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.793749</td>\n",
       "      <td>0.740354</td>\n",
       "      <td>0.038121</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.527096</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.148084</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>3</td>\n",
       "      <td>6.235615</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.709112</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.794046</td>\n",
       "      <td>0.741586</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.537154</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.152896</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>3</td>\n",
       "      <td>6.591461</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.710981</td>\n",
       "      <td>0.723085</td>\n",
       "      <td>0.794345</td>\n",
       "      <td>0.742804</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.534441</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>0.159231</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>3</td>\n",
       "      <td>6.967615</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.712820</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.744006</td>\n",
       "      <td>0.036127</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2.529152</td>\n",
       "      <td>0.015547</td>\n",
       "      <td>0.152358</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>3</td>\n",
       "      <td>7.365234</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.714628</td>\n",
       "      <td>0.725998</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.745193</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.528522</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>3</td>\n",
       "      <td>7.785544</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.716401</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.795261</td>\n",
       "      <td>0.746362</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.544496</td>\n",
       "      <td>0.014711</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>3</td>\n",
       "      <td>8.22984</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.728830</td>\n",
       "      <td>0.795572</td>\n",
       "      <td>0.747513</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.567607</td>\n",
       "      <td>0.038303</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>3</td>\n",
       "      <td>8.69949</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.719834</td>\n",
       "      <td>0.730216</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>0.748645</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2.534452</td>\n",
       "      <td>0.023226</td>\n",
       "      <td>0.157459</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>3</td>\n",
       "      <td>9.195942</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.721489</td>\n",
       "      <td>0.731582</td>\n",
       "      <td>0.796203</td>\n",
       "      <td>0.749758</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2.558559</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.153858</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>3</td>\n",
       "      <td>9.720724</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.723101</td>\n",
       "      <td>0.732928</td>\n",
       "      <td>0.796523</td>\n",
       "      <td>0.750851</td>\n",
       "      <td>0.032543</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2.544996</td>\n",
       "      <td>0.016906</td>\n",
       "      <td>0.153470</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>3</td>\n",
       "      <td>10.275454</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.734253</td>\n",
       "      <td>0.796845</td>\n",
       "      <td>0.751922</td>\n",
       "      <td>0.032006</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2.568983</td>\n",
       "      <td>0.052670</td>\n",
       "      <td>0.152346</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>3</td>\n",
       "      <td>10.861841</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.726187</td>\n",
       "      <td>0.735559</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.752972</td>\n",
       "      <td>0.031486</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2.644766</td>\n",
       "      <td>0.154391</td>\n",
       "      <td>0.154250</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>3</td>\n",
       "      <td>11.481691</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.727658</td>\n",
       "      <td>0.736844</td>\n",
       "      <td>0.797498</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2.521396</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.152462</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>3</td>\n",
       "      <td>12.136914</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.729079</td>\n",
       "      <td>0.738110</td>\n",
       "      <td>0.797828</td>\n",
       "      <td>0.755006</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2.552497</td>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>3</td>\n",
       "      <td>12.829528</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.730448</td>\n",
       "      <td>0.739357</td>\n",
       "      <td>0.798161</td>\n",
       "      <td>0.755988</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2.530550</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.154230</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>3</td>\n",
       "      <td>13.561668</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.731764</td>\n",
       "      <td>0.740585</td>\n",
       "      <td>0.798496</td>\n",
       "      <td>0.756948</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.547940</td>\n",
       "      <td>0.024529</td>\n",
       "      <td>0.155281</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>3</td>\n",
       "      <td>14.335588</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.733027</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>0.798833</td>\n",
       "      <td>0.757885</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2.539176</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.153599</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>3</td>\n",
       "      <td>15.153674</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.734236</td>\n",
       "      <td>0.742985</td>\n",
       "      <td>0.799172</td>\n",
       "      <td>0.758798</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2.566712</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.153588</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>3</td>\n",
       "      <td>16.018444</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.735391</td>\n",
       "      <td>0.744159</td>\n",
       "      <td>0.799513</td>\n",
       "      <td>0.759688</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2.547329</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.152779</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "      <td>16.932565</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.736492</td>\n",
       "      <td>0.745317</td>\n",
       "      <td>0.799856</td>\n",
       "      <td>0.760555</td>\n",
       "      <td>0.028023</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2.544193</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.152784</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>3</td>\n",
       "      <td>17.898852</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.737537</td>\n",
       "      <td>0.746458</td>\n",
       "      <td>0.800201</td>\n",
       "      <td>0.761399</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2.529992</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>0.153983</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>3</td>\n",
       "      <td>18.920281</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.738529</td>\n",
       "      <td>0.747584</td>\n",
       "      <td>0.800547</td>\n",
       "      <td>0.762220</td>\n",
       "      <td>0.027352</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2.568401</td>\n",
       "      <td>0.043341</td>\n",
       "      <td>0.153972</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'polynomial_features__degree': 3, 'ridge_regr...</td>\n",
       "      <td>0.739468</td>\n",
       "      <td>0.748694</td>\n",
       "      <td>0.800894</td>\n",
       "      <td>0.763019</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.021067      0.009673         0.008253        0.004890   \n",
       "1        0.014285      0.000981         0.004365        0.000508   \n",
       "2        0.013519      0.000257         0.004030        0.000105   \n",
       "3        0.013020      0.000138         0.003922        0.000065   \n",
       "4        0.012997      0.000027         0.003867        0.000032   \n",
       "5        0.012979      0.000224         0.003873        0.000055   \n",
       "6        0.013046      0.000023         0.003895        0.000021   \n",
       "7        0.013278      0.000147         0.004147        0.000274   \n",
       "8        0.013287      0.000353         0.003917        0.000030   \n",
       "9        0.013251      0.000092         0.004128        0.000253   \n",
       "10       0.013765      0.000063         0.004221        0.000003   \n",
       "11       0.014017      0.000221         0.004211        0.000075   \n",
       "12       0.013505      0.000154         0.004073        0.000034   \n",
       "13       0.013500      0.000193         0.004040        0.000080   \n",
       "14       0.013214      0.000068         0.003917        0.000009   \n",
       "15       0.013317      0.000063         0.003997        0.000028   \n",
       "16       0.013247      0.000086         0.003945        0.000016   \n",
       "17       0.013799      0.000593         0.004040        0.000057   \n",
       "18       0.013320      0.000224         0.004131        0.000221   \n",
       "19       0.013911      0.000203         0.004129        0.000066   \n",
       "20       0.013516      0.000092         0.004092        0.000031   \n",
       "21       0.013593      0.000157         0.004044        0.000058   \n",
       "22       0.013692      0.000363         0.003989        0.000064   \n",
       "23       0.013273      0.000072         0.003963        0.000051   \n",
       "24       0.013227      0.000143         0.003986        0.000052   \n",
       "25       0.013474      0.000136         0.004045        0.000035   \n",
       "26       0.013588      0.000161         0.004050        0.000047   \n",
       "27       0.013763      0.000373         0.004247        0.000195   \n",
       "28       0.014188      0.000193         0.004516        0.000347   \n",
       "29       0.013735      0.000205         0.004085        0.000051   \n",
       "30       0.131188      0.007256         0.016158        0.000241   \n",
       "31       0.123715      0.001884         0.017334        0.001706   \n",
       "32       0.124478      0.001244         0.016280        0.000428   \n",
       "33       0.140053      0.025214         0.015898        0.000181   \n",
       "34       0.124167      0.001095         0.016040        0.000164   \n",
       "35       0.126594      0.001251         0.016120        0.000152   \n",
       "36       0.130767      0.006383         0.017586        0.001938   \n",
       "37       0.123524      0.002396         0.015943        0.000162   \n",
       "38       0.124602      0.002136         0.016258        0.000322   \n",
       "39       0.132031      0.010212         0.016212        0.000080   \n",
       "40       0.125439      0.000910         0.016560        0.000266   \n",
       "41       0.125390      0.001158         0.016277        0.000097   \n",
       "42       0.122423      0.001068         0.015874        0.000094   \n",
       "43       0.128364      0.007115         0.017996        0.002850   \n",
       "44       0.124015      0.003692         0.017563        0.002454   \n",
       "45       0.121034      0.000773         0.015717        0.000231   \n",
       "46       0.134903      0.019672         0.015811        0.000144   \n",
       "47       0.120816      0.001199         0.015881        0.000188   \n",
       "48       0.123184      0.002085         0.015974        0.000135   \n",
       "49       0.120703      0.001010         0.016010        0.000305   \n",
       "50       0.122317      0.000728         0.018499        0.003648   \n",
       "51       0.149985      0.024305         0.016614        0.000903   \n",
       "52       0.123631      0.000112         0.016298        0.000299   \n",
       "53       0.126974      0.000330         0.016428        0.000093   \n",
       "54       0.147489      0.016318         0.016348        0.000256   \n",
       "55       0.123858      0.001132         0.015899        0.000182   \n",
       "56       0.122233      0.000404         0.015965        0.000164   \n",
       "57       0.125739      0.000528         0.015912        0.000079   \n",
       "58       0.122161      0.001625         0.015795        0.000318   \n",
       "59       0.122870      0.000915         0.016224        0.000168   \n",
       "60       2.677843      0.186299         0.158307        0.007691   \n",
       "61       2.573720      0.013329         0.158314        0.002948   \n",
       "62       2.643627      0.042948         0.158113        0.001728   \n",
       "63       2.641217      0.123821         0.155143        0.000299   \n",
       "64       2.563514      0.027400         0.154237        0.000413   \n",
       "65       2.603444      0.078869         0.154386        0.000929   \n",
       "66       2.571187      0.050437         0.154642        0.001312   \n",
       "67       2.527269      0.002510         0.152877        0.000313   \n",
       "68       2.527096      0.008534         0.148084        0.004692   \n",
       "69       2.537154      0.009200         0.152896        0.001628   \n",
       "70       2.534441      0.018354         0.159231        0.007995   \n",
       "71       2.529152      0.015547         0.152358        0.001285   \n",
       "72       2.528522      0.009573         0.155357        0.000815   \n",
       "73       2.544496      0.014711         0.153630        0.001158   \n",
       "74       2.567607      0.038303         0.154518        0.000918   \n",
       "75       2.534452      0.023226         0.157459        0.003579   \n",
       "76       2.558559      0.016352         0.153858        0.000931   \n",
       "77       2.544996      0.016906         0.153470        0.000319   \n",
       "78       2.568983      0.052670         0.152346        0.000368   \n",
       "79       2.644766      0.154391         0.154250        0.000627   \n",
       "80       2.521396      0.011941         0.152462        0.000914   \n",
       "81       2.552497      0.041997         0.152542        0.001175   \n",
       "82       2.530550      0.006828         0.154230        0.001238   \n",
       "83       2.547940      0.024529         0.155281        0.001220   \n",
       "84       2.539176      0.024508         0.153599        0.000639   \n",
       "85       2.566712      0.025605         0.153588        0.000448   \n",
       "86       2.547329      0.027255         0.152779        0.000517   \n",
       "87       2.544193      0.026888         0.152784        0.000856   \n",
       "88       2.529992      0.011151         0.153983        0.000947   \n",
       "89       2.568401      0.043341         0.153972        0.000461   \n",
       "\n",
       "   param_polynomial_features__degree param_ridge_regression__alpha  \\\n",
       "0                                  1                           4.0   \n",
       "1                                  1                      4.228267   \n",
       "2                                  1                       4.46956   \n",
       "3                                  1                      4.724624   \n",
       "4                                  1                      4.994243   \n",
       "5                                  1                      5.279248   \n",
       "6                                  1                      5.580518   \n",
       "7                                  1                       5.89898   \n",
       "8                                  1                      6.235615   \n",
       "9                                  1                      6.591461   \n",
       "10                                 1                      6.967615   \n",
       "11                                 1                      7.365234   \n",
       "12                                 1                      7.785544   \n",
       "13                                 1                       8.22984   \n",
       "14                                 1                       8.69949   \n",
       "15                                 1                      9.195942   \n",
       "16                                 1                      9.720724   \n",
       "17                                 1                     10.275454   \n",
       "18                                 1                     10.861841   \n",
       "19                                 1                     11.481691   \n",
       "20                                 1                     12.136914   \n",
       "21                                 1                     12.829528   \n",
       "22                                 1                     13.561668   \n",
       "23                                 1                     14.335588   \n",
       "24                                 1                     15.153674   \n",
       "25                                 1                     16.018444   \n",
       "26                                 1                     16.932565   \n",
       "27                                 1                     17.898852   \n",
       "28                                 1                     18.920281   \n",
       "29                                 1                          20.0   \n",
       "30                                 2                           4.0   \n",
       "31                                 2                      4.228267   \n",
       "32                                 2                       4.46956   \n",
       "33                                 2                      4.724624   \n",
       "34                                 2                      4.994243   \n",
       "35                                 2                      5.279248   \n",
       "36                                 2                      5.580518   \n",
       "37                                 2                       5.89898   \n",
       "38                                 2                      6.235615   \n",
       "39                                 2                      6.591461   \n",
       "40                                 2                      6.967615   \n",
       "41                                 2                      7.365234   \n",
       "42                                 2                      7.785544   \n",
       "43                                 2                       8.22984   \n",
       "44                                 2                       8.69949   \n",
       "45                                 2                      9.195942   \n",
       "46                                 2                      9.720724   \n",
       "47                                 2                     10.275454   \n",
       "48                                 2                     10.861841   \n",
       "49                                 2                     11.481691   \n",
       "50                                 2                     12.136914   \n",
       "51                                 2                     12.829528   \n",
       "52                                 2                     13.561668   \n",
       "53                                 2                     14.335588   \n",
       "54                                 2                     15.153674   \n",
       "55                                 2                     16.018444   \n",
       "56                                 2                     16.932565   \n",
       "57                                 2                     17.898852   \n",
       "58                                 2                     18.920281   \n",
       "59                                 2                          20.0   \n",
       "60                                 3                           4.0   \n",
       "61                                 3                      4.228267   \n",
       "62                                 3                       4.46956   \n",
       "63                                 3                      4.724624   \n",
       "64                                 3                      4.994243   \n",
       "65                                 3                      5.279248   \n",
       "66                                 3                      5.580518   \n",
       "67                                 3                       5.89898   \n",
       "68                                 3                      6.235615   \n",
       "69                                 3                      6.591461   \n",
       "70                                 3                      6.967615   \n",
       "71                                 3                      7.365234   \n",
       "72                                 3                      7.785544   \n",
       "73                                 3                       8.22984   \n",
       "74                                 3                       8.69949   \n",
       "75                                 3                      9.195942   \n",
       "76                                 3                      9.720724   \n",
       "77                                 3                     10.275454   \n",
       "78                                 3                     10.861841   \n",
       "79                                 3                     11.481691   \n",
       "80                                 3                     12.136914   \n",
       "81                                 3                     12.829528   \n",
       "82                                 3                     13.561668   \n",
       "83                                 3                     14.335588   \n",
       "84                                 3                     15.153674   \n",
       "85                                 3                     16.018444   \n",
       "86                                 3                     16.932565   \n",
       "87                                 3                     17.898852   \n",
       "88                                 3                     18.920281   \n",
       "89                                 3                          20.0   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'polynomial_features__degree': 1, 'ridge_regr...           0.782295   \n",
       "1   {'polynomial_features__degree': 1, 'ridge_regr...           0.782296   \n",
       "2   {'polynomial_features__degree': 1, 'ridge_regr...           0.782297   \n",
       "3   {'polynomial_features__degree': 1, 'ridge_regr...           0.782298   \n",
       "4   {'polynomial_features__degree': 1, 'ridge_regr...           0.782299   \n",
       "5   {'polynomial_features__degree': 1, 'ridge_regr...           0.782300   \n",
       "6   {'polynomial_features__degree': 1, 'ridge_regr...           0.782302   \n",
       "7   {'polynomial_features__degree': 1, 'ridge_regr...           0.782303   \n",
       "8   {'polynomial_features__degree': 1, 'ridge_regr...           0.782304   \n",
       "9   {'polynomial_features__degree': 1, 'ridge_regr...           0.782306   \n",
       "10  {'polynomial_features__degree': 1, 'ridge_regr...           0.782307   \n",
       "11  {'polynomial_features__degree': 1, 'ridge_regr...           0.782309   \n",
       "12  {'polynomial_features__degree': 1, 'ridge_regr...           0.782311   \n",
       "13  {'polynomial_features__degree': 1, 'ridge_regr...           0.782312   \n",
       "14  {'polynomial_features__degree': 1, 'ridge_regr...           0.782314   \n",
       "15  {'polynomial_features__degree': 1, 'ridge_regr...           0.782316   \n",
       "16  {'polynomial_features__degree': 1, 'ridge_regr...           0.782318   \n",
       "17  {'polynomial_features__degree': 1, 'ridge_regr...           0.782320   \n",
       "18  {'polynomial_features__degree': 1, 'ridge_regr...           0.782322   \n",
       "19  {'polynomial_features__degree': 1, 'ridge_regr...           0.782324   \n",
       "20  {'polynomial_features__degree': 1, 'ridge_regr...           0.782326   \n",
       "21  {'polynomial_features__degree': 1, 'ridge_regr...           0.782328   \n",
       "22  {'polynomial_features__degree': 1, 'ridge_regr...           0.782331   \n",
       "23  {'polynomial_features__degree': 1, 'ridge_regr...           0.782333   \n",
       "24  {'polynomial_features__degree': 1, 'ridge_regr...           0.782335   \n",
       "25  {'polynomial_features__degree': 1, 'ridge_regr...           0.782338   \n",
       "26  {'polynomial_features__degree': 1, 'ridge_regr...           0.782340   \n",
       "27  {'polynomial_features__degree': 1, 'ridge_regr...           0.782343   \n",
       "28  {'polynomial_features__degree': 1, 'ridge_regr...           0.782345   \n",
       "29  {'polynomial_features__degree': 1, 'ridge_regr...           0.782348   \n",
       "30  {'polynomial_features__degree': 2, 'ridge_regr...           0.784198   \n",
       "31  {'polynomial_features__degree': 2, 'ridge_regr...           0.784209   \n",
       "32  {'polynomial_features__degree': 2, 'ridge_regr...           0.784220   \n",
       "33  {'polynomial_features__degree': 2, 'ridge_regr...           0.784232   \n",
       "34  {'polynomial_features__degree': 2, 'ridge_regr...           0.784244   \n",
       "35  {'polynomial_features__degree': 2, 'ridge_regr...           0.784257   \n",
       "36  {'polynomial_features__degree': 2, 'ridge_regr...           0.784271   \n",
       "37  {'polynomial_features__degree': 2, 'ridge_regr...           0.784285   \n",
       "38  {'polynomial_features__degree': 2, 'ridge_regr...           0.784301   \n",
       "39  {'polynomial_features__degree': 2, 'ridge_regr...           0.784317   \n",
       "40  {'polynomial_features__degree': 2, 'ridge_regr...           0.784334   \n",
       "41  {'polynomial_features__degree': 2, 'ridge_regr...           0.784351   \n",
       "42  {'polynomial_features__degree': 2, 'ridge_regr...           0.784370   \n",
       "43  {'polynomial_features__degree': 2, 'ridge_regr...           0.784390   \n",
       "44  {'polynomial_features__degree': 2, 'ridge_regr...           0.784410   \n",
       "45  {'polynomial_features__degree': 2, 'ridge_regr...           0.784432   \n",
       "46  {'polynomial_features__degree': 2, 'ridge_regr...           0.784455   \n",
       "47  {'polynomial_features__degree': 2, 'ridge_regr...           0.784479   \n",
       "48  {'polynomial_features__degree': 2, 'ridge_regr...           0.784504   \n",
       "49  {'polynomial_features__degree': 2, 'ridge_regr...           0.784531   \n",
       "50  {'polynomial_features__degree': 2, 'ridge_regr...           0.784558   \n",
       "51  {'polynomial_features__degree': 2, 'ridge_regr...           0.784587   \n",
       "52  {'polynomial_features__degree': 2, 'ridge_regr...           0.784618   \n",
       "53  {'polynomial_features__degree': 2, 'ridge_regr...           0.784649   \n",
       "54  {'polynomial_features__degree': 2, 'ridge_regr...           0.784683   \n",
       "55  {'polynomial_features__degree': 2, 'ridge_regr...           0.784717   \n",
       "56  {'polynomial_features__degree': 2, 'ridge_regr...           0.784754   \n",
       "57  {'polynomial_features__degree': 2, 'ridge_regr...           0.784792   \n",
       "58  {'polynomial_features__degree': 2, 'ridge_regr...           0.784831   \n",
       "59  {'polynomial_features__degree': 2, 'ridge_regr...           0.784873   \n",
       "60  {'polynomial_features__degree': 3, 'ridge_regr...           0.693430   \n",
       "61  {'polynomial_features__degree': 3, 'ridge_regr...           0.695435   \n",
       "62  {'polynomial_features__degree': 3, 'ridge_regr...           0.697434   \n",
       "63  {'polynomial_features__degree': 3, 'ridge_regr...           0.699422   \n",
       "64  {'polynomial_features__degree': 3, 'ridge_regr...           0.701397   \n",
       "65  {'polynomial_features__degree': 3, 'ridge_regr...           0.703356   \n",
       "66  {'polynomial_features__degree': 3, 'ridge_regr...           0.705297   \n",
       "67  {'polynomial_features__degree': 3, 'ridge_regr...           0.707217   \n",
       "68  {'polynomial_features__degree': 3, 'ridge_regr...           0.709112   \n",
       "69  {'polynomial_features__degree': 3, 'ridge_regr...           0.710981   \n",
       "70  {'polynomial_features__degree': 3, 'ridge_regr...           0.712820   \n",
       "71  {'polynomial_features__degree': 3, 'ridge_regr...           0.714628   \n",
       "72  {'polynomial_features__degree': 3, 'ridge_regr...           0.716401   \n",
       "73  {'polynomial_features__degree': 3, 'ridge_regr...           0.718137   \n",
       "74  {'polynomial_features__degree': 3, 'ridge_regr...           0.719834   \n",
       "75  {'polynomial_features__degree': 3, 'ridge_regr...           0.721489   \n",
       "76  {'polynomial_features__degree': 3, 'ridge_regr...           0.723101   \n",
       "77  {'polynomial_features__degree': 3, 'ridge_regr...           0.724668   \n",
       "78  {'polynomial_features__degree': 3, 'ridge_regr...           0.726187   \n",
       "79  {'polynomial_features__degree': 3, 'ridge_regr...           0.727658   \n",
       "80  {'polynomial_features__degree': 3, 'ridge_regr...           0.729079   \n",
       "81  {'polynomial_features__degree': 3, 'ridge_regr...           0.730448   \n",
       "82  {'polynomial_features__degree': 3, 'ridge_regr...           0.731764   \n",
       "83  {'polynomial_features__degree': 3, 'ridge_regr...           0.733027   \n",
       "84  {'polynomial_features__degree': 3, 'ridge_regr...           0.734236   \n",
       "85  {'polynomial_features__degree': 3, 'ridge_regr...           0.735391   \n",
       "86  {'polynomial_features__degree': 3, 'ridge_regr...           0.736492   \n",
       "87  {'polynomial_features__degree': 3, 'ridge_regr...           0.737537   \n",
       "88  {'polynomial_features__degree': 3, 'ridge_regr...           0.738529   \n",
       "89  {'polynomial_features__degree': 3, 'ridge_regr...           0.739468   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.784909           0.797389         0.788198        0.006586   \n",
       "1            0.784907           0.797391         0.788198        0.006587   \n",
       "2            0.784905           0.797393         0.788198        0.006588   \n",
       "3            0.784902           0.797395         0.788198        0.006589   \n",
       "4            0.784899           0.797398         0.788199        0.006591   \n",
       "5            0.784896           0.797400         0.788199        0.006592   \n",
       "6            0.784893           0.797403         0.788199        0.006593   \n",
       "7            0.784890           0.797405         0.788199        0.006595   \n",
       "8            0.784887           0.797408         0.788200        0.006596   \n",
       "9            0.784883           0.797411         0.788200        0.006598   \n",
       "10           0.784879           0.797414         0.788200        0.006599   \n",
       "11           0.784875           0.797417         0.788200        0.006601   \n",
       "12           0.784871           0.797421         0.788201        0.006603   \n",
       "13           0.784866           0.797424         0.788201        0.006605   \n",
       "14           0.784861           0.797428         0.788201        0.006607   \n",
       "15           0.784856           0.797432         0.788201        0.006609   \n",
       "16           0.784851           0.797436         0.788201        0.006611   \n",
       "17           0.784845           0.797440         0.788202        0.006614   \n",
       "18           0.784838           0.797445         0.788202        0.006616   \n",
       "19           0.784832           0.797449         0.788202        0.006619   \n",
       "20           0.784825           0.797454         0.788202        0.006622   \n",
       "21           0.784817           0.797459         0.788202        0.006625   \n",
       "22           0.784809           0.797465         0.788201        0.006628   \n",
       "23           0.784800           0.797470         0.788201        0.006631   \n",
       "24           0.784791           0.797476         0.788201        0.006635   \n",
       "25           0.784781           0.797482         0.788200        0.006638   \n",
       "26           0.784771           0.797488         0.788200        0.006642   \n",
       "27           0.784760           0.797494         0.788199        0.006646   \n",
       "28           0.784748           0.797501         0.788198        0.006651   \n",
       "29           0.784735           0.797508         0.788197        0.006656   \n",
       "30           0.806143           0.815954         0.802098        0.013276   \n",
       "31           0.806145           0.815972         0.802108        0.013278   \n",
       "32           0.806146           0.815990         0.802119        0.013279   \n",
       "33           0.806148           0.816009         0.802130        0.013281   \n",
       "34           0.806150           0.816029         0.802141        0.013282   \n",
       "35           0.806152           0.816049         0.802153        0.013283   \n",
       "36           0.806154           0.816070         0.802165        0.013285   \n",
       "37           0.806156           0.816091         0.802178        0.013286   \n",
       "38           0.806158           0.816113         0.802191        0.013287   \n",
       "39           0.806161           0.816136         0.802204        0.013288   \n",
       "40           0.806163           0.816159         0.802219        0.013289   \n",
       "41           0.806165           0.816183         0.802233        0.013289   \n",
       "42           0.806167           0.816208         0.802248        0.013290   \n",
       "43           0.806170           0.816233         0.802264        0.013290   \n",
       "44           0.806172           0.816259         0.802281        0.013290   \n",
       "45           0.806175           0.816285         0.802297        0.013290   \n",
       "46           0.806177           0.816312         0.802315        0.013289   \n",
       "47           0.806179           0.816339         0.802333        0.013288   \n",
       "48           0.806182           0.816367         0.802351        0.013287   \n",
       "49           0.806184           0.816395         0.802370        0.013285   \n",
       "50           0.806186           0.816424         0.802389        0.013283   \n",
       "51           0.806188           0.816453         0.802410        0.013281   \n",
       "52           0.806190           0.816483         0.802430        0.013278   \n",
       "53           0.806192           0.816512         0.802451        0.013274   \n",
       "54           0.806194           0.816542         0.802473        0.013270   \n",
       "55           0.806195           0.816572         0.802495        0.013265   \n",
       "56           0.806196           0.816603         0.802517        0.013260   \n",
       "57           0.806197           0.816633         0.802541        0.013254   \n",
       "58           0.806197           0.816664         0.802564        0.013247   \n",
       "59           0.806197           0.816694         0.802588        0.013239   \n",
       "60           0.709088           0.791751         0.731423        0.043135   \n",
       "61           0.710707           0.792029         0.732724        0.042396   \n",
       "62           0.712311           0.792309         0.734018        0.041663   \n",
       "63           0.713901           0.792592         0.735305        0.040937   \n",
       "64           0.715475           0.792877         0.736583        0.040219   \n",
       "65           0.717033           0.793165         0.737852        0.039509   \n",
       "66           0.718573           0.793456         0.739109        0.038810   \n",
       "67           0.720096           0.793749         0.740354        0.038121   \n",
       "68           0.721600           0.794046         0.741586        0.037443   \n",
       "69           0.723085           0.794345         0.742804        0.036779   \n",
       "70           0.724551           0.794647         0.744006        0.036127   \n",
       "71           0.725998           0.794953         0.745193        0.035491   \n",
       "72           0.727424           0.795261         0.746362        0.034868   \n",
       "73           0.728830           0.795572         0.747513        0.034262   \n",
       "74           0.730216           0.795886         0.748645        0.033672   \n",
       "75           0.731582           0.796203         0.749758        0.033099   \n",
       "76           0.732928           0.796523         0.750851        0.032543   \n",
       "77           0.734253           0.796845         0.751922        0.032006   \n",
       "78           0.735559           0.797170         0.752972        0.031486   \n",
       "79           0.736844           0.797498         0.754000        0.030985   \n",
       "80           0.738110           0.797828         0.755006        0.030504   \n",
       "81           0.739357           0.798161         0.755988        0.030041   \n",
       "82           0.740585           0.798496         0.756948        0.029598   \n",
       "83           0.741794           0.798833         0.757885        0.029175   \n",
       "84           0.742985           0.799172         0.758798        0.028771   \n",
       "85           0.744159           0.799513         0.759688        0.028387   \n",
       "86           0.745317           0.799856         0.760555        0.028023   \n",
       "87           0.746458           0.800201         0.761399        0.027678   \n",
       "88           0.747584           0.800547         0.762220        0.027352   \n",
       "89           0.748694           0.800894         0.763019        0.027045   \n",
       "\n",
       "    rank_test_score  \n",
       "0                59  \n",
       "1                58  \n",
       "2                56  \n",
       "3                55  \n",
       "4                54  \n",
       "5                53  \n",
       "6                51  \n",
       "7                50  \n",
       "8                49  \n",
       "9                47  \n",
       "10               46  \n",
       "11               44  \n",
       "12               43  \n",
       "13               41  \n",
       "14               40  \n",
       "15               38  \n",
       "16               36  \n",
       "17               35  \n",
       "18               33  \n",
       "19               31  \n",
       "20               32  \n",
       "21               34  \n",
       "22               37  \n",
       "23               39  \n",
       "24               42  \n",
       "25               45  \n",
       "26               48  \n",
       "27               52  \n",
       "28               57  \n",
       "29               60  \n",
       "30               30  \n",
       "31               29  \n",
       "32               28  \n",
       "33               27  \n",
       "34               26  \n",
       "35               25  \n",
       "36               24  \n",
       "37               23  \n",
       "38               22  \n",
       "39               21  \n",
       "40               20  \n",
       "41               19  \n",
       "42               18  \n",
       "43               17  \n",
       "44               16  \n",
       "45               15  \n",
       "46               14  \n",
       "47               13  \n",
       "48               12  \n",
       "49               11  \n",
       "50               10  \n",
       "51                9  \n",
       "52                8  \n",
       "53                7  \n",
       "54                6  \n",
       "55                5  \n",
       "56                4  \n",
       "57                3  \n",
       "58                2  \n",
       "59                1  \n",
       "60               90  \n",
       "61               89  \n",
       "62               88  \n",
       "63               87  \n",
       "64               86  \n",
       "65               85  \n",
       "66               84  \n",
       "67               83  \n",
       "68               82  \n",
       "69               81  \n",
       "70               80  \n",
       "71               79  \n",
       "72               78  \n",
       "73               77  \n",
       "74               76  \n",
       "75               75  \n",
       "76               74  \n",
       "77               73  \n",
       "78               72  \n",
       "79               71  \n",
       "80               70  \n",
       "81               69  \n",
       "82               68  \n",
       "83               67  \n",
       "84               66  \n",
       "85               65  \n",
       "86               64  \n",
       "87               63  \n",
       "88               62  \n",
       "89               61  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same estimator as before\n",
    "estimator = Pipeline([\n",
    "        (\"polynomial_features\", PolynomialFeatures()),\n",
    "        (\"regression\", lr)])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3],    \n",
    "}\n",
    "\n",
    "grid2 = GridSearchCV(estimator, params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('polynomial_features',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('regression', LinearRegression())]),\n",
       "             param_grid={'polynomial_features__degree': [1, 2, 3]})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7885635017266841, {'polynomial_features__degree': 1})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.best_score_,grid2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphas = np.geomspace(1e-9, 1e0, num=10)\n",
    "\n",
    "# Same estimator as before\n",
    "estimator = Pipeline([(\"scaler\", StandardScaler()),\n",
    "        (\"polynomial_features\", PolynomialFeatures()),\n",
    "        (\"lasso_regression\", Ridge())])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3],\n",
    "    'lasso_regression__alpha': np.geomspace(1e-9, 1e0, num=10)\n",
    "}\n",
    "\n",
    "grid3 = GridSearchCV(estimator, params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2893, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 24.6 GiB for an array with shape (2894, 1139295) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2893, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 307, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 1788, in transform\n",
      "    dtype=X.dtype, order=self.order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.1 TiB for an array with shape (2894, 573824915) and data type float64\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.83581709        nan        nan 0.83596178        nan        nan\n",
      " 0.83597641        nan        nan 0.83597792        nan        nan\n",
      " 0.83597806        nan        nan 0.83597807        nan        nan\n",
      " 0.83597803        nan        nan 0.83597763        nan        nan\n",
      " 0.83597362        nan        nan 0.83593346        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('polynomial_features',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('lasso_regression', Ridge())]),\n",
       "             param_grid={'lasso_regression__alpha': array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00]),\n",
       "                         'polynomial_features__degree': [1, 2, 3]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8019508239720018,\n",
       " {'lasso_regression__alpha': 1.0, 'polynomial_features__degree': 2})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.best_score_,grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "OtkQbtzdY1Vi",
    "J14GMEjoLPsv",
    "lE3znEfL_Wcs"
   ],
   "name": "car_dekho.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
